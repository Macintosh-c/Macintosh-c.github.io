<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>macintosh-c&#39;s blog</title>
  <icon>https://www.gravatar.com/avatar/aec2ea475468bef1ef6aafb32d76a922</icon>
  <subtitle>当你的才华撑不起你的野心时，就应该静下心来好好学习。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://macintosh-c.coding.me/"/>
  <updated>2021-10-12T02:11:39.377Z</updated>
  <id>http://macintosh-c.coding.me/</id>
  
  <author>
    <name>Macintosh-c</name>
    <email>657582163@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mycat基于postgreSQL主从读写分离及mycat容器化部署</title>
    <link href="http://macintosh-c.coding.me/2021/09/23/Databases/postgre/mycat%E9%83%A8%E7%BD%B2postgre%E5%B9%B6%E9%83%A8%E7%BD%B2K8s/"/>
    <id>http://macintosh-c.coding.me/2021/09/23/Databases/postgre/mycat部署postgre并部署K8s/</id>
    <published>2021-09-23T04:20:31.000Z</published>
    <updated>2021-10-12T02:11:39.377Z</updated>
    
    <content type="html"><![CDATA[<h2 id="mycat基于postgreSQL集群实现读写分离"><a href="#mycat基于postgreSQL集群实现读写分离" class="headerlink" title="mycat基于postgreSQL集群实现读写分离"></a>mycat基于postgreSQL集群实现读写分离</h2><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>  Mycat作为独立的数据库中间件，我们只需要进行相关的配置，就可以非常方便的帮我们实现水平切分、垂直切分、读写分离等功能，但PostgreSQL的主从复制需要我们通过其它方式实现。这里假设我们已经搭建好相关的环境，下面就开始我们的实践！</p><p>mycat下载地址：<a href="http://dl.mycat.org.cn" target="_blank" rel="noopener">http://dl.mycat.org.cn</a></p><h4 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h4><p>PostgreSQL(Version : 12)主从环境搭建</p><p>对应数据库建立（以下例子中使用的都是默认存在的postgres_test数据库，可以不用额外添加）</p><h4 id="配置server-xml"><a href="#配置server-xml" class="headerlink" title="配置server.xml"></a>配置server.xml</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;user name=&quot;postgres_app&quot;&gt;</span><br><span class="line">&lt;property name=&quot;password&quot;&gt;Softtek@123&lt;/property&gt;</span><br><span class="line">&lt;property name=&quot;schemas&quot;&gt;postgres_test&lt;/property&gt;</span><br><span class="line">&lt;property name=&quot;readOnly&quot;&gt;false&lt;/property&gt;</span><br><span class="line">&lt;property name=&quot;defaultSchema&quot;&gt;postgres_test&lt;/property&gt;</span><br><span class="line">&lt;/user&gt;</span><br></pre></td></tr></table></figure><h4 id="配置schema-xml"><a href="#配置schema-xml" class="headerlink" title="配置schema.xml"></a>配置schema.xml</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;schema name=&quot;postgres_test&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;1000&quot; randomDataNode=&quot;dp1&quot;&gt;</span><br><span class="line">&lt;table name=&quot;test_ms&quot; dataNode=&quot;dp1&quot; /&gt;</span><br><span class="line">&lt;/schema&gt;</span><br><span class="line"></span><br><span class="line">&lt;dataNode name=&quot;dp1&quot; dataHost=&quot;postgres1&quot; database=&quot;public&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 数据源 --&gt;</span><br><span class="line">&lt;dataHost name=&quot;postgres1&quot; maxCon=&quot;2000&quot; minCon=&quot;10&quot; balance=&quot;3&quot; writeType=&quot;0&quot; dbType=&quot;postgresql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt;</span><br><span class="line">&lt;heartbeat&gt;select user&lt;/heartbeat&gt;</span><br><span class="line">&lt;!-- can have multi write hosts --&gt;</span><br><span class="line">&lt;writeHost host=&quot;hostM1&quot; url=&quot;jdbc:postgresql://172.16.98.236:5432/postgres_test&quot; user=&quot;postgres&quot; password=&quot;postgres&quot;&gt;</span><br><span class="line">&lt;!-- 读库 --&gt;</span><br><span class="line">&lt;readHost host=&quot;hostS1&quot; url=&quot;jdbc:postgresql://172.16.98.239:5432/postgres_test&quot; user=&quot;postgres&quot; password=&quot;postgres&quot; /&gt;</span><br><span class="line">&lt;/writeHost&gt;</span><br><span class="line">&lt;/dataHost&gt;</span><br></pre></td></tr></table></figure><p>踩坑记录：<br>1.dbDriver 属性<br>指定连接后端数据库使用的 Driver，目前可选的值有 native 和 jdbc。使用 native 的话，因为这个值执行的是二进制的 mysql 协议，所以可以使用 mysql 和 maridb。其他类型的数据库则需要使用 JDBC 驱动来支持</p><p>引述《Mycat权威指南》里面的原话:</p><blockquote><blockquote><p>从 1.6 版本开始支持 postgresql 的 native 原始协议。<br> 如果使用 JDBC 的话需要将符合 JDBC4 标准的驱动 JAR 包放到 MYCAT\lib 目录下，并检查驱动 JAR 包中<br> 包括如下目录结构的文件：META-INF\services\java.sql.Driver。在这个文件内写上具体的 Driver 类名，例如：<br> com.mysql.jdbc.Driver。</p></blockquote></blockquote><p>亲测当使用native协议时，即使postgresql的密码配置正确，mycat仍无法正常连接到PG，除非在PG的配置文件中忽略掉该端请求的密码校验。所以建议使用jdbc驱动，需要提前下载好postgre的jar包，直接置于mycat的lib目录下即可。</p><p>2.关于postgre的schema的配置<br>这个是与mysql不同的概念，postgresql中，用户创建的所有对象都被创建在指定的schema(或namespace)中。其他用户可能拥有、也可能不拥有访问这些对象的权限，甚至都不可以在对应的schema中创建对象。当未配置schema时，启动mycat，创建表时会报no schema has been selected to create in，除非在表名前指定schema，默认为public也要指定。以及查询表时也需要显式指定。这就带来了麻烦。这里schema的配置是在dataNode标签的database属性中，而实际的数据库名在writeHost和readHost的jdbc连接url中定义。</p><h4 id="配置rule-xml"><a href="#配置rule-xml" class="headerlink" title="配置rule.xml"></a>配置rule.xml</h4><p>因未涉及到分库分表，仅仅读写分离，所以不需要额外配置rule规则，配置方式同mysql。</p><p>按上述配置好后，启动mycat便可以实现postgre的读写分离。</p><h2 id="K8s容器化部署"><a href="#K8s容器化部署" class="headerlink" title="K8s容器化部署"></a>K8s容器化部署</h2><h4 id="镜像制作"><a href="#镜像制作" class="headerlink" title="镜像制作"></a>镜像制作</h4><p>MyCAT 是使用 JAVA 语言进行编程开发，使用前需要安装 JAVA 运行环境(JRE) 。<br>提前下载好 jdk，mycat包，以及postgre的驱动包（使用jdbc的连接方式）。<br>另外准备好server.xml,schema.xml,log4f2.xml三个配置文件，并已经正确配置好逻辑库，登录账户密码，postgreSQL的连接。</p><p>编写dockerfile：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:centos7</span><br><span class="line"></span><br><span class="line">ADD Mycat-server-1.6.7.4-release-20200105164103-linux.tar.gz /</span><br><span class="line"></span><br><span class="line">ADD jdk-8u151-linux-x64.tar.gz /</span><br><span class="line">ADD postgresql-42.1.4.jar /mycat/lib/</span><br><span class="line">ENV JAVA_HOME /jdk1.8.0_151</span><br><span class="line">ENV MYCAT_HOME /mycat</span><br><span class="line"></span><br><span class="line">ENV PATH /usr/bin:$JAVA_HOME/bin:$MYCAT_HOME/bin:PATH</span><br><span class="line"></span><br><span class="line">CMD mycat console</span><br></pre></td></tr></table></figure></p><p>根据dockerfile生成本地镜像：</p><p>docker build -t mycat-server .     (根据Dockerfile起镜像)</p><h4 id="本地启动docker容器调试"><a href="#本地启动docker容器调试" class="headerlink" title="本地启动docker容器调试"></a>本地启动docker容器调试</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name mycat-server -p 8066:8066 -p 9066:9066 -v /mycat/postgres-mycat/server.xml:/mycat/conf/server.xml -v /mycat/postgres-mycat/schema.xml:/mycat/conf/schema.xml -v /mycat/postgres-mycat/log4j2.xml:/mycat/conf/log4j2.xml mycat-server</span><br></pre></td></tr></table></figure><p>便可以通过本地的mysql客户端连接：<br>mysql -h 127.0.0.1 -P 8066 -u postgres_app -pSofttek@123</p><p>####推送至镜像仓库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker tag mycat-server harbor.local.irain.top/sbux/mycat</span><br><span class="line">docker push harbor.local.irain.top/sbux/mycat:latest</span><br></pre></td></tr></table></figure></p><h4 id="部署k8s"><a href="#部署k8s" class="headerlink" title="部署k8s"></a>部署k8s</h4><p>1.创建项目mycat<br><img src="/img/Databases/postgre/k8s1.png" alt="image"></p><p>2.在该项目下创建镜像仓库的密钥，方便拉取镜像<br><img src="/img/Databases/postgre/k8s2.png" alt="image"></p><p>3.新增三个配置，用户将客制化的server.xml,schema.xml,log4f2.xml配置记载到容器的服务中<br><img src="/img/Databases/postgre/k8s3.png" alt="image"></p><p>4.新建无状态服务，指定好刚刚推送的镜像<br><img src="/img/Databases/postgre/k8s4.png" alt="image"></p><p>5.以及配置好使用的资源上限<br><img src="/img/Databases/postgre/k8s5.png" alt="image"></p><p>6.访问的策略，暴露出8066和9066端口<br><img src="/img/Databases/postgre/k8s6.png" alt="image"></p><p>7.挂载上刚刚新建的三个配置文件到容器中/mycat/conf目录下，用于替换掉原始的配置<br><img src="/img/Databases/postgre/k8s7.png" alt="image"></p><p>8.待服务启动成功，配置好外网访问即可<br><img src="/img/Databases/postgre/k8s8.png" alt="image"></p><p>即可通过mysql -h 172.16.98.152 -P 31062 -u postgres_app -pSofttek@123 连接测试。</p><h4 id="关于监控"><a href="#关于监控" class="headerlink" title="关于监控"></a>关于监控</h4><p>日记层面：mycat的日记文件位于 /mycat/logs/mycat.log 文件，可通过log4j2.xml配置日记等级为info或debug。sql异常或者postgre服务异常导致不可用，均在日记中有异常抛出。可采集该日记文件，基于elk做监控。</p><p>运行态：k8s容器的弹性伸缩有效的防止了一些高并发下导致的资源不足问题，其他依赖于对于服务器cpu，内存的实时监控工具。</p><h2 id="应用端改造（-springboot）"><a href="#应用端改造（-springboot）" class="headerlink" title="应用端改造（ springboot）"></a>应用端改造（ springboot）</h2><p>需要改用连mysql的方式去配置，Mycat会在后端做好对其它数据库的连接。<br>原本直连postgre配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spring.datasource.type=com.alibaba.druid.pool.DruidDataSource</span><br><span class="line">spring.datasource.url=jdbc:postgresql://172.16.98.236:5432/postgres_test?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useServerPrepStmts=true&amp;allowMultiQueries=true</span><br><span class="line">spring.datasource.username=postgres</span><br><span class="line">spring.datasource.password=postgres</span><br><span class="line">spring.datasource.driver-class-name=org.postgresql.Driver</span><br></pre></td></tr></table></figure></p><p>改直连mycat，使用mysql方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spring.datasource.type=com.alibaba.druid.pool.DruidDataSource</span><br><span class="line">spring.datasource.url=jdbc:mysql://172.16.98.152:31062/postgres_test?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useServerPrepStmts=true&amp;allowPublicKeyRetrieval=true</span><br><span class="line">spring.datasource.username=postgres_app</span><br><span class="line">spring.datasource.password=Softtek@123</span><br><span class="line">spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver</span><br></pre></td></tr></table></figure></p><p><img src="/img/Databases/postgre/k8s9.png" alt="image"></p><p>maven加上对于mysql的驱动依赖，其他无变动，当然如果应用部署在K8s容器平台，和mycat同一个项目下，就可通过服务名+端口8066来连接，不需要通过外网的方式访问，实验接口前后返回一致，如下：</p><p><img src="/img/Databases/postgre/k8s10.png" alt="image"></p><p>本示例仅在java springboot框架下，其他语言框架可参考。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;mycat基于postgreSQL集群实现读写分离&quot;&gt;&lt;a href=&quot;#mycat基于postgreSQL集群实现读写分离&quot; class=&quot;headerlink&quot; title=&quot;mycat基于postgreSQL集群实现读写分离&quot;&gt;&lt;/a&gt;mycat基于post
      
    
    </summary>
    
      <category term="mycat" scheme="http://macintosh-c.coding.me/categories/mycat/"/>
    
    
      <category term="mycat容器化部署" scheme="http://macintosh-c.coding.me/tags/mycat%E5%AE%B9%E5%99%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>PostgreSql的pg_hba.conf文件详解</title>
    <link href="http://macintosh-c.coding.me/2021/09/23/Databases/postgre/PostgreSql%E7%9A%84pg_hba.conf%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"/>
    <id>http://macintosh-c.coding.me/2021/09/23/Databases/postgre/PostgreSql的pg_hba.conf文件详解/</id>
    <published>2021-09-23T04:20:30.000Z</published>
    <updated>2021-10-12T01:56:56.633Z</updated>
    
    <content type="html"><![CDATA[<h2 id="PostgreSQL的pg-hba-conf文件讲解"><a href="#PostgreSQL的pg-hba-conf文件讲解" class="headerlink" title="PostgreSQL的pg_hba.conf文件讲解"></a>PostgreSQL的pg_hba.conf文件讲解</h2><p>pg_hba.conf为PostgreSQL的访问策略配置文件，默认位于/var/lib/pgsql/10/data/目录（PostgreSQL10）。<br>该配置文件有5个参数，分别为：TYPE（主机类型）、DATABASE（数据库名）、USER（用户名）、ADDRESS（IP地址和掩码）、METHOD（加密方法）</p><h4 id="TYPE，有4个值"><a href="#TYPE，有4个值" class="headerlink" title="TYPE，有4个值"></a>TYPE，有4个值</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">local：使用Unix-domainsocket</span><br><span class="line">host：使用TCP/IP连接，可以是SSL的，也可以不是</span><br><span class="line">hostssl：必须是SSL的</span><br><span class="line">hostnossl：必须是非SSL的</span><br></pre></td></tr></table></figure><h4 id="DATABASE"><a href="#DATABASE" class="headerlink" title="DATABASE"></a>DATABASE</h4><p>数据库名，可以是”all”, “sameuser”, “samerole”, “replication”。all表示所有，但不包括replication。多个数据库用“,”隔开。</p><h4 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h4><p>用户名，可以为”all”，表示所有，也可以具体指定一个用户。多个用户用“,”隔开。和DATABASE一样，也可以将配置放到文件中，文件名加上前缀@</p><h4 id="ADDRESS"><a href="#ADDRESS" class="headerlink" title="ADDRESS"></a>ADDRESS</h4><p>可以是为一个主机名，或者由IP地址和CIDR掩码组成。掩码可以为0-32（IPv4）或者0-128（IPv6）间的一个整数，32表示子网掩码为255.255.255.255，24表示子网掩码为255.255.255.0。主机名以“.”开头。samehost可以匹配所有主机、samenet可以匹配同一个掩码内的所有主机。<br>例：192.168.10.122/32表示单一主机，192.168.10.0/24表示192.168.0.1~192.168.0.255网段内所有主机，0.0.0.0/0表示所有主机。</p><h4 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h4><p>密码加密策略，password表示以明文方式发送密码，md5和scram-sha-256会以对应的方式加密再发送密码。<br>ident是Linux下PostgreSQL默认的local认证方式，<br>获取客户的操作系统名（对于 TCP/IP 联接，用户的身份是通过与运行在客户端上的 ident 服务器联接进行判断的，对于本地联接，它是从操作系统获取的。） 然后检查一下，看看用户是否允许以要求的数据库用户进行联接， 方法是参照在 ident 关键字后面声明的映射。<br>凡是能正确登录服务器的操作系统用户（注：不是数据库用户）就能使用本用户映射的数据库用户不需密码登录数据库。用户映射文件为pg_ident.conf，这个文件记录着与操作系统用户匹配的数据库用户，如果某操作系统用户在本文件中没有映射用户，则默认的映射数据库用户与操作系统用户同名。比如，服务器上有名为user1的操作系统用户，同时数据库上也有同名的数据库用户，user1登录操作系统后可以直接输入psql，以user1数据库用户身份登录数据库且不需密码。很多初学者都会遇到psql -U username登录数据库却出现“username ident 认证失败”的错误，明明数据库用户已经createuser。原因就在于此，使用了ident认证方式，却没有同名的操作系统用户或没有相应的映射用户。解决方案：在pg_ident.conf中添加映射用户<br>host        all                all          127.0.0.1/32         ident  username      // username表示某个没有建立映射的用户  ，不写默认可以用postgres用户登录，postgres用户安装的时候自动创建，相当于mysql的root用户<br>md5是常用的密码认证方式，如果你不使用ident，最好使用md5。密码是以md5形式传送给数据库，较安全，且不需建立同名的操作系统用户。<br>比如客户端pgAdmin III 需要连接数据库就需要配置<br>host        all                all          0.0.0.0/0              md5<br>trust<br>无条件地允许联接。这个方法允许任何可以与PostgreSQL 数据库服务器联接的用户以他们期望的任意 PostgreSQL 数据库用户身份进行联接，而不需要口令。建议测试用<br>reject<br>联接无条件拒绝。常用于从一个组中”过滤”某些主机。<br>crypt<br>要求客户端提供一个 crypt() 加密的口令用于认证。 7.2 以前的客户端只能支持 crypt。 对于 7.2 以及以后的客户端，我们建议使用 md5。<br>password<br>要求客户端提供一个未加密的口令进行认证。 因为口令是以明文形式在网络上传递的， 所以我们不应该在不安全的网络上使用这个方式。建议测试用<br>krb4<br>用 Kerberos V4 认证用户。只有在进行 TCP/IP 联接的时候才能用。  （译注：Kerberos，”克尔波洛斯”，故希腊神话冥王哈得斯的多头看门狗。 Kerberos 是 MIT 开发出来的基与对称加密算法的认证协议和/或密钥交换方法。 其特点是需要两个不同用途的服务器，一个用于认证身份， 一个用于通道两端用户的密钥交换。同时 Kerberos 对网络时间同步要求比较高，以防止回放攻击，因此通常伴随 NTP 服务。）<br>krb5<br>用 Kerberos V5 认证用户。只有在进行 TCP/IP 联接的时候才能用。  （译注：Kerberos V5 是上面 V4 的改良，主要是不再依赖 DES 算法， 同时增加了一些新特性。）<br>pam<br>使用操作系统提供的可插入的认证模块服务 （Pluggable Authentication Modules） （PAM）来认证。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;PostgreSQL的pg-hba-conf文件讲解&quot;&gt;&lt;a href=&quot;#PostgreSQL的pg-hba-conf文件讲解&quot; class=&quot;headerlink&quot; title=&quot;PostgreSQL的pg_hba.conf文件讲解&quot;&gt;&lt;/a&gt;PostgreS
      
    
    </summary>
    
      <category term="Postgre" scheme="http://macintosh-c.coding.me/categories/Postgre/"/>
    
    
      <category term="Postgre安装" scheme="http://macintosh-c.coding.me/tags/Postgre%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>Postgre主从搭建</title>
    <link href="http://macintosh-c.coding.me/2021/09/23/Databases/postgre/Postgre%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"/>
    <id>http://macintosh-c.coding.me/2021/09/23/Databases/postgre/Postgre主从搭建/</id>
    <published>2021-09-23T04:20:29.000Z</published>
    <updated>2021-09-23T07:24:48.130Z</updated>
    
    <content type="html"><![CDATA[<p>有需求使用mycat来实现postgre主从集群的读写分离，于是首先开始搭建pg的主从集群</p><h2 id="centos-PG集群搭建"><a href="#centos-PG集群搭建" class="headerlink" title="centos PG集群搭建"></a>centos PG集群搭建</h2><h4 id="安装PG"><a href="#安装PG" class="headerlink" title="安装PG"></a>安装PG</h4><p>1、安装之前首先查看软件是否已经安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep postgresql</span><br><span class="line"></span><br><span class="line">#若存在，需要卸载使用 yum remove postgresql</span><br></pre></td></tr></table></figure><p>2、安装postgresql和postgresql-server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm</span><br><span class="line">sudo yum install -y postgresql12-server</span><br></pre></td></tr></table></figure><p>3、环境变量<br>创建目录，给与权限<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /data/</span><br><span class="line">mkdir pgdata</span><br><span class="line">chown -R postgres:postgres ./pgdata</span><br></pre></td></tr></table></figure></p><p>修改环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/lib/systemd/system/postgresql-12.service</span><br><span class="line"></span><br><span class="line"># 修改 Environment</span><br><span class="line">Environment=PGDATA=/data/pgdata/ #PGDATA一般是数据盘</span><br><span class="line"></span><br><span class="line"># 重载</span><br><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure></p><p>4、启动数据库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 初始化数据库</span><br><span class="line">/usr/pgsql-12/bin/postgresql-12-setup initdb</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">systemctl start postgresql-12</span><br></pre></td></tr></table></figure></p><p>5、创建用户<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">su - postgres</span><br><span class="line">psql</span><br><span class="line"># 用于pgpool</span><br><span class="line">create role pgpool with login password &apos;postgres&apos;;</span><br><span class="line"># 用于主从</span><br><span class="line">create role repl login replication encrypted password &apos;postgres&apos;;</span><br><span class="line"></span><br><span class="line"># 修改postgres密码</span><br><span class="line">alter user postgres with password &apos;postgres&apos;;</span><br></pre></td></tr></table></figure></p><h4 id="配置主从"><a href="#配置主从" class="headerlink" title="配置主从"></a>配置主从</h4><p>主节点配置<br>1、pg_hba.conf<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 修改data（/data/pgdata）下面的配置</span><br><span class="line">vi /data/pgdata/pg_hba.conf</span><br><span class="line"></span><br><span class="line"># 追加</span><br><span class="line">host    all            all     0.0.0.0/0          md5 </span><br><span class="line">host    replication    repl    本机ip/32    trust</span><br><span class="line">host    replication    repl    节点1 ip/32    trust #从节点1</span><br><span class="line">...</span><br><span class="line">host    replication    repl    节点n ip/32    trust #从节点n</span><br><span class="line"></span><br><span class="line">host    all            all     本机ip 最后一位替换为0/24      md5</span><br></pre></td></tr></table></figure></p><p>2、postgresql.conf<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 修改data（/data/pgdata）下面的配置</span><br><span class="line">vi /data/pgdata/postgresql.conf</span><br><span class="line"></span><br><span class="line"># 修改内容</span><br><span class="line">listen_addresses = &apos;*&apos; #开启后子节点才能访问#监听所有ip</span><br><span class="line">archive_mode = on       #开启归档模式</span><br><span class="line">max_connections = 21000</span><br><span class="line">archive_command = &apos;cp &quot;%p&quot; &quot;/var/lib/pgsql/archivedir/%f&quot;&apos; #归档命令</span><br><span class="line">max_wal_senders = 10</span><br><span class="line">max_replication_slots = 10</span><br><span class="line">wal_level = replica</span><br><span class="line">hot_standby = on   #热备模式</span><br><span class="line">wal_log_hints = on</span><br></pre></td></tr></table></figure></p><p>3、重启主库<br>systemctl restart postgresql-12</p><p>从节点配置<br>1、拉取主库配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#删除从库data目录下文件</span><br><span class="line">rm ‐rf data/*</span><br><span class="line"></span><br><span class="line"># 拉取主库配置，主库记得开5432端口</span><br><span class="line">#pg_basebackup -h 主节点ip -U repl -D /data/pgdata -X stream -P </span><br><span class="line">pg_basebackup -h 172.16.98.236 -p 5432 -U repl -Fp -Xs -Pv -R -D /data/pgdata</span><br><span class="line"></span><br><span class="line"># 开通端口</span><br><span class="line">iptables -I INPUT -p tcp --dport 5432 -j ACCEPT</span><br></pre></td></tr></table></figure></p><p>2、修改配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># postgresql.conf修改内容</span><br><span class="line">    primary_conninfo = &apos;host=主节点ip port=5432 user=repl(主节点对应账号) password=密码&apos;</span><br><span class="line">    recovery_target_timeline = latest  </span><br><span class="line">    hot_standby = on    #说明这台机器不仅用于数据归档，还可以用于数据查询</span><br><span class="line">    max_standby_streaming_delay = 30s</span><br><span class="line">    wal_receiver_status_interval = 10s</span><br><span class="line">    hot_standby_feedback = on   #r出现错误复制，向主机反馈</span><br></pre></td></tr></table></figure></p><p>3、修改从库standby.signal配置文件<br>pgsql 12版本，不再支持recovery.conf</p><p>standby_mode 配置在 standby.signal 中配置<br>primary_conninfo 配置在 postgresql.conf 中配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># standby.signal修改内容</span><br><span class="line">    standby_mode = on</span><br></pre></td></tr></table></figure><p>4、重启从库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#重启</span><br><span class="line">systemctl restart postgresql-12</span><br><span class="line"></span><br><span class="line">#也可以stop再start</span><br><span class="line">systemctl stop postgresql-12</span><br><span class="line">systemctl start postgresql-12</span><br></pre></td></tr></table></figure></p><h4 id="检查集群"><a href="#检查集群" class="headerlink" title="检查集群"></a>检查集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 进入主库</span><br><span class="line">su - postgres</span><br><span class="line"># 进入sql</span><br><span class="line">psql</span><br><span class="line"></span><br><span class="line"># 查询同步状态，完成的话显示n行</span><br><span class="line">select client_addr,usename,backend_start,application_name,sync_state,sync_priority FROM pg_stat_replication;</span><br><span class="line"></span><br><span class="line"># 添加数据库 </span><br><span class="line">CREATE DATABASE test;</span><br><span class="line"></span><br><span class="line"># 进入从库查看，发现新的库test</span><br><span class="line"># 执行新建操作，警告only-read</span><br></pre></td></tr></table></figure><p>参考：</p><blockquote><blockquote><p><a href="https://www.cnblogs.com/wuhao-grow-uo/archive/2021/08/19/15162596.html" target="_blank" rel="noopener">https://www.cnblogs.com/wuhao-grow-uo/archive/2021/08/19/15162596.html</a><br><a href="https://www.cnblogs.com/x-j-p/p/13085588.html" target="_blank" rel="noopener">https://www.cnblogs.com/x-j-p/p/13085588.html</a></p></blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;有需求使用mycat来实现postgre主从集群的读写分离，于是首先开始搭建pg的主从集群&lt;/p&gt;
&lt;h2 id=&quot;centos-PG集群搭建&quot;&gt;&lt;a href=&quot;#centos-PG集群搭建&quot; class=&quot;headerlink&quot; title=&quot;centos PG集群搭建
      
    
    </summary>
    
      <category term="Postgre" scheme="http://macintosh-c.coding.me/categories/Postgre/"/>
    
    
      <category term="Postgre安装" scheme="http://macintosh-c.coding.me/tags/Postgre%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>动态代理</title>
    <link href="http://macintosh-c.coding.me/2021/06/28/spring/Springboot/spring%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"/>
    <id>http://macintosh-c.coding.me/2021/06/28/spring/Springboot/spring动态代理/</id>
    <published>2021-06-27T17:29:05.000Z</published>
    <updated>2021-06-29T06:40:50.576Z</updated>
    
    <content type="html"><![CDATA[<p>近日在迁移一个项目时，需要升级springboot版本，从1.5到2.0，碰到一个关于动态代理的坑，加深了对于spring动态代理的理解。由于项目中用到webservice，当时使用的apache cxf，在升级后，一直报错，一番查找原因发现该jar内有用final修饰的方法，在升级到2.0默认采用Cglib的代理方式不行，还是需要使用jdk的代理方式，使用spring.aop.proxy-target-class=false属性设置后，依然不生效，这一块还是走到Cglib的代理，但是实际debug却发现默认加载的应该是jdk的代理方式，就比较纳闷，继续跟踪方法，springboot中有很多标签都会改变动态代理的方式，如@EnableAsync，@EnableCaching，于是发现出问题的类上使用了@RefreshScope标签，为了动态刷新nacos的配置，点进源码一看，默认采用的是CGLIB，于是去掉该注解测试，程序立即通畅了。</p><h2 id="动态代理介绍"><a href="#动态代理介绍" class="headerlink" title="动态代理介绍"></a>动态代理介绍</h2><p>与AspectJ的静态代理不同，Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。</p><p>　　Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。</p><p>　　如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，是利用asm开源包，可以在运行时动态的生成某个类的子类。注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。</p><p>这里有注意的几点如下：</p><ul><li><p>从Spring 3.2以后不再将CGLIB放在项目的classpath下，而是将CGLIB类打包放在spring-core下面的org.springframework中。这个就意味着基于CGLIB的动态代理与JDK的动态代理在支持“just works”就一样了。</p></li><li><p>在Spring 4.0中，因为CGLIB代理实例是通过Objenesis创建的，所以代理对象的构造器不再有两次调用。</p></li><li><p>在 Spring Boot 2.0 中，Spring Boot现在默认使用CGLIB动态代理(基于类的动态代理), 包括AOP. 如果需要基于接口的动态代理(JDK基于接口的动态代理) , 需要设置spring.aop.proxy-target-class属性为false。</p></li></ul><p>参考：</p><p><a href="https://www.cnblogs.com/onlymate/p/9630788.html" target="_blank" rel="noopener">https://www.cnblogs.com/onlymate/p/9630788.html</a></p><p><a href="https://blog.csdn.net/weixin_41325595/article/details/103576207" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41325595/article/details/103576207</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近日在迁移一个项目时，需要升级springboot版本，从1.5到2.0，碰到一个关于动态代理的坑，加深了对于spring动态代理的理解。由于项目中用到webservice，当时使用的apache cxf，在升级后，一直报错，一番查找原因发现该jar内有用final修饰的方
      
    
    </summary>
    
      <category term="Springboot" scheme="http://macintosh-c.coding.me/categories/Springboot/"/>
    
    
      <category term="Spring aop" scheme="http://macintosh-c.coding.me/tags/Spring-aop/"/>
    
  </entry>
  
  <entry>
    <title>三、数据迁移</title>
    <link href="http://macintosh-c.coding.me/2021/06/25/Databases/mycat/3.%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/"/>
    <id>http://macintosh-c.coding.me/2021/06/25/Databases/mycat/3.数据迁移/</id>
    <published>2021-06-25T06:49:36.000Z</published>
    <updated>2021-10-09T10:10:17.327Z</updated>
    
    <content type="html"><![CDATA[<p>涉及到数据迁移，即原数据库的数据导出，以及新数据库的导入，这里主要是使用mysqldump进行数据迁移，mycat即使用mycat端口号，提前配置号分库分表规则，来初始化数据即可。对于非mysql的原数据源，可以使用文件方式通过load data批量导入形式来进行数据迁移。</p><h3 id="1-使用mysqldump进行数据迁移"><a href="#1-使用mysqldump进行数据迁移" class="headerlink" title="1. 使用mysqldump进行数据迁移"></a>1. 使用mysqldump进行数据迁移</h3><h4 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h4><p>源数据库全库备份：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./mysqldump -uroot -p -h10.87.20.62 -c --skip-add-locks --flush-logs --single-transaction --master-data=2  --set-gtid-purged=OFF customer_center &gt; /data/mysqldump/customer_center2.sql</span><br></pre></td></tr></table></figure></p><p>当然也可以迁移一个库中的某几个表:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -c -–skip-add-locks databaseName table1 table2&gt; /root/someTables.sql</span><br></pre></td></tr></table></figure><p>也可迁移一个表中的部分数据，加参数–where实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -c -–skip-add-locks databaseName tableName --where=&quot; id &gt; 900 &quot; &gt; /root/onetableDataWithCondition.sql</span><br></pre></td></tr></table></figure><p>参数详细说明：<br>迁移前确保mysql库和mycat库中的表名一样（mycat库中只需要有表名配置在schema.xml文件中即可）<br>-c参数不可少，-c, 全称为–complete-insert 表示使用完整的insert语句(用列名字)。 不带列名，mycat导入会报错。mycat需要根据列名来分库分表。<br>-–skip-add-locks表示导数据时不加锁，如果加锁涉及多分片时容易导致死锁。<br>–flush-logs表示备份之前刷新bin_log  后面的增量备份就从新的bin-log开始<br>–set-gtid-purged=OFF时，在会记录binlog日志，如果不加，不记录binlog日志，所以在我们做主从用了gtid时，用mysqldump备份时就要加–set-gtid-purged=OFF，否则你在主上导入恢复了数据，主没有了binlog日志，从库则不会被同步<br>-B 表示仅复制testdb并且包含create database testdb<br>–single-transaction  innodb下保证数据一致性<br>–master-data 该参数有两个值1和2，默认为1，mysqldump导出数据时，当这个参数的值为1的时候，mysqldump出来的文件就会包括CHANGE MASTER TO这个语句，CHANGE MASTER TO后面紧接着就是file和position的记录，在slave上导入数据时就会执行这个语句，salve就会根据指定这个文件位置从master端复制binlog。当这个值是2的时候，chang master to也是会写到dump文件里面去的，但是这个语句是被注释的状态。</p><p>备份存储过程触发器及事件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    --events: 事件调度，默认为开启，显示关闭使用--skip-events </span><br><span class="line">    --routines: 存储过程及函数, 默认为开启，显示关闭使用--skip-routines </span><br><span class="line">    --triggers: 触发器，默认为开启，关闭使用--skip-triggers</span><br></pre></td></tr></table></figure></p><p>只备份表结构或数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--no-data：只导出建表语句。 </span><br><span class="line">--no-create-info：只导出数据，不导出表结构。</span><br></pre></td></tr></table></figure></p><p>更详解参数：<a href="https://www.cnblogs.com/chenmh/p/5300370.html" target="_blank" rel="noopener">https://www.cnblogs.com/chenmh/p/5300370.html</a></p><h4 id="还原"><a href="#还原" class="headerlink" title="还原"></a>还原</h4><p>连接mycat：<br>mysql -uusername -ppassword -h172.17.xxx.xxx -P8066<br>切换到指定的数据库： use databaseName;<br>导入脚本： source /root/databaseName.sql; </p><h4 id="使用binlog增量还原"><a href="#使用binlog增量还原" class="headerlink" title="使用binlog增量还原"></a>使用binlog增量还原</h4><p>此方式对于基于mycat的增量导入没成功，仅实验mysql到mysql的增量迁移成功，且仅限迁移前后数据库名必须相同。</p><p>mysqldump后查看binlog日记状态，并记录文件名<br>将后续新增的binlog文件拷贝到目标数据库服务器，使用mysqlbinlog来读取binlog二进制文件，并导入到目标库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqlbinlog --database=testdb /var/backup/mysql-bin.000003 | mysql -uroot -pPassword.123 -v testdb</span><br></pre></td></tr></table></figure><p>补充：mysqlbinlog使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">简单了解binlog</span><br><span class="line">MySQL的二进制日志binlog可以说是MySQL最重要的日志，它记录了所有的DDL和DML语句（除了数据查询语句select），以事件形式记录，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。</span><br><span class="line">===========================================================</span><br><span class="line">DDL</span><br><span class="line">   - Data Definition Language 数据库定义语言</span><br><span class="line">主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用。</span><br><span class="line"></span><br><span class="line">DML</span><br><span class="line">   - Data Manipulation Language 数据操纵语言</span><br><span class="line">主要的命令是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言</span><br><span class="line">===========================================================</span><br><span class="line"></span><br><span class="line">mysqlbinlog常见的选项有以下几个：</span><br><span class="line">--start-datetime：从二进制日志中读取指定等于时间戳或者晚于本地服务器的时间</span><br><span class="line">--stop-datetime：从二进制日志中读取指定小于时间戳或者等于本地服务器的时间 取值和上述一样</span><br><span class="line">--start-position：从二进制日志中读取指定position 事件位置作为开始。</span><br><span class="line">--stop-position：从二进制日志中读取指定position 事件位置作为事件截至</span><br><span class="line"></span><br><span class="line">===========================================================</span><br><span class="line"></span><br><span class="line">一般来说开启binlog日志大概会有1%的性能损耗。</span><br><span class="line"></span><br><span class="line">binlog日志有两个最重要的使用场景</span><br><span class="line">1）MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到</span><br><span class="line">master-slave数据一致的目的。</span><br><span class="line">2）自然就是数据恢复了，通过使用mysqlbinlog工具来使恢复数据。</span><br><span class="line"></span><br><span class="line">binlog日志包括两类文件</span><br><span class="line">1）二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件</span><br><span class="line">2）二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。</span><br><span class="line"></span><br><span class="line">常用举例：</span><br><span class="line">1）binlog内容输出到终端或文本文件 </span><br><span class="line">mysqlbinlog binlog_files | more</span><br><span class="line">mysqlbinlog binlog_files &gt; tmpfile</span><br><span class="line"></span><br><span class="line">2）多个binlog log日志的还原最好将所有文件使用一个连接完成，如果使用不同连接的话有时会导致不安全 ，例如：</span><br><span class="line">[root@localhost /]# mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!!</span><br><span class="line">[root@localhost /]# mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!!</span><br><span class="line"></span><br><span class="line">如果第一个日志包含创建临时表语句CREATE TEMPORARY TABLE，第二个日志要使用该临时表，第一个导入binlog日志的进程退出后临时表会被删除，执行第二个日志文件要使用临时表时会因找不到而报 “unknown table.” </span><br><span class="line"></span><br><span class="line">建议的方法： </span><br><span class="line">方法1： 所有二进制文件放在单个连接里</span><br><span class="line">[root@localhost /]# mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p</span><br><span class="line"></span><br><span class="line">方法2： 将所有二进制文件写在一个文件里执行 </span><br><span class="line">[root@localhost /]# mysqlbinlog binlog.000001 &gt;  /tmp/statements.sql</span><br><span class="line">[root@localhost /]# mysqlbinlog binlog.000002 &gt;&gt; /tmp/statements.sql</span><br><span class="line">[root@localhost /]# mysql -u root -p -e &quot;source /tmp/statements.sql&quot;</span><br><span class="line"></span><br><span class="line">使用方法二如果二进制文件里包含GTID信息需要过滤掉</span><br><span class="line">[root@localhost /]# mysqlbinlog --skip-gtids binlog.000001 &gt;  /tmp/dump.sql</span><br><span class="line">[root@localhost /]# mysqlbinlog --skip-gtids binlog.000002 &gt;&gt; /tmp/dump.sql</span><br><span class="line">[root@localhost /]# mysql -u root -p -e &quot;source /tmp/dump.sql&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3）通过事件的时间来恢复 </span><br><span class="line">我们可以通过参数--start-datetime 和 --stop-datetime指定恢复binlog日志的起止时间点，时间使用DATETIME格式。 比如在时间点2005-04-20 10:00:00我们删除掉一个库，我们要恢复该时间点前的所有日志 </span><br><span class="line">[root@localhost /]# mysqlbinlog --stop-datetime=&quot;2005-04-20 9:59:59&quot; /usr/local/mysql/data/binlog.123456 | mysql -u root -p</span><br><span class="line"></span><br><span class="line">4）通过事件的位置来恢复</span><br><span class="line">我们可以通过参数--start-position 和 --stop-position指定恢复binlog日志的起止位置点，通过位置的恢复需要我们有更加精细的操作，例如在某个时间点我们执行了错误的语句，且这个时间点前后都有大并发操作，要确定破坏性sql的时间点，我们可以先导出大致的时间段的日志到文件以缩小查找范围，再去分析和确定，确定好需要跳过的位置之后，我们就可以进行恢复了</span><br><span class="line">[root@localhost /]# mysqlbinlog --stop-position=368312 /usr/local/mysql/data/binlog.123456 | mysql -u root -p</span><br><span class="line">[root@localhost /]# mysqlbinlog --start-position=368315 /usr/local/mysql/data/binlog.123456 | mysql -u root -p</span><br><span class="line"></span><br><span class="line">注：mysqlbinlog工具的输出会在每条sql语句前增加 SET TIMESTAMP语句，恢复的数据及mysql日志反映当前时间。</span><br></pre></td></tr></table></figure></p><h3 id="2-使用load-data批量导入"><a href="#2-使用load-data批量导入" class="headerlink" title="2. 使用load data批量导入"></a>2. 使用load data批量导入</h3><p>导出为CSV文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from sys_user into outfile &apos;/var/lib/mysql-files/sys_user.csv&apos; FIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos; ESCAPED BY &apos;\\&apos; LINES TERMINATED BY &apos;\n&apos;;</span><br></pre></td></tr></table></figure></p><p>导入CSV文件数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data infile &apos;/opt/data/dump/sys_user.csv&apos; REPLACE INTO TABLE SYS_USER FIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos; ESCAPED BY &apos;\\&apos; LINES TERMINATED BY &apos;\n&apos; (USER_ID,DEPT_ID,USER_NAME,NICK_NAME,USER_TYPE,EMAIL,PHONENUMBER,SEX,AVATAR,PASSWORD,STATUS,DEL_FLAG,LOGIN_IP,LOGIN_DATE,CREATE_BY,CREATE_TIME,UPDATE_BY,UPDATE_TIME,REMARK);</span><br></pre></td></tr></table></figure></p><p>注意：如果数据中可能包含一些特殊字符，比如分割符转义符等，建议用引号扩起来，通过OPTIONALLY ENCLOSED BY ‘”’指定。如果这样还不行，可以把字段值中的引号替换成\”。<br>如果指定local关键词，则表明从客户端主机读文件。如果local没指定，文件必须位于mycat所在的服务器上。<br>可以通过fields terminated by指定字符之间的分割符号，默认值为\t<br>通过lines terminated by可以指定行之间的换行符。默认为\n,这里注意有些windows上的文本文件的换行符可能为\r\n，由于是不可见字符，所以请小心检查。<br>character set 指定文件的编码，建议跟mysql的编码一致，否则可能乱码。其中字符集编码必须用引号扩起来，否则会解析出错。<br>还可以通过replace | ignore指定遇到重复记录是替换还是忽略。<br>目前列名必须指定，且必须包括分片字段，否则没办法确定路由。<br>标准load data语句： LOAD DATA语句,同样被记录到binlog,不过是内部的机制。</p><p>参考：<a href="https://blog.csdn.net/kimva/article/details/78875154" target="_blank" rel="noopener">https://blog.csdn.net/kimva/article/details/78875154</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;涉及到数据迁移，即原数据库的数据导出，以及新数据库的导入，这里主要是使用mysqldump进行数据迁移，mycat即使用mycat端口号，提前配置号分库分表规则，来初始化数据即可。对于非mysql的原数据源，可以使用文件方式通过load data批量导入形式来进行数据迁移。
      
    
    </summary>
    
      <category term="Mycat" scheme="http://macintosh-c.coding.me/categories/Mycat/"/>
    
    
      <category term="mycat" scheme="http://macintosh-c.coding.me/tags/mycat/"/>
    
  </entry>
  
  <entry>
    <title>二、Mycat安装与配置</title>
    <link href="http://macintosh-c.coding.me/2021/06/25/Databases/mycat/2.Mycat%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    <id>http://macintosh-c.coding.me/2021/06/25/Databases/mycat/2.Mycat安装与配置/</id>
    <published>2021-06-25T04:49:36.000Z</published>
    <updated>2021-08-12T01:49:47.994Z</updated>
    
    <content type="html"><![CDATA[<p>按照上一章步骤搭建完mysql的集群，且验证主从复制没有问题，本篇来安装mycat</p><p>先理解下面几个概念：</p><ul><li><p>垂直分表：将一个表按照字段分成多表，每个表存储其中一部分字段。</p></li><li><p>垂直分库：是指按照业务将表进行分类，分布到不同的数据库上面，每个库可以放在不同的服务器上，它的核心理念是专库专用。</p></li><li>水平分库：是把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上。</li><li>水平分表：是在同一个数据库内，把同一个表的数据按一定规则拆到多个表中。</li></ul><h3 id="Mycat安装"><a href="#Mycat安装" class="headerlink" title="Mycat安装"></a>Mycat安装</h3><p>下载安装包地址：<a href="http://dl.mycat.org.cn" target="_blank" rel="noopener">http://dl.mycat.org.cn</a></p><p>下载完解压缩到：/usr/local/mycat 目录即可</p><h3 id="Mycat-配置说明"><a href="#Mycat-配置说明" class="headerlink" title="Mycat 配置说明"></a>Mycat 配置说明</h3><ol><li>Schema.xml </li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line">Schema.xml 作为 MyCat中重要的配置文件之一，管理着 MyCat的逻辑库、表、分片规则、DataNode以及DataSource。弄懂这些配置，是正确使用MyCat的前提。</span><br><span class="line"></span><br><span class="line">schema 标签</span><br><span class="line"></span><br><span class="line">该标签用于定义MyCat实例中的逻辑库，MyCat可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用 schema 标签来划分这些不同的逻辑库。</span><br><span class="line"></span><br><span class="line">&lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt;</span><br><span class="line">&lt;table name=&quot;tableName&quot; primaryKey=&quot;id&quot; dataNode=&quot;dn1,dn2&quot; rule=&quot;rule1&quot;/&gt;</span><br><span class="line">&lt;/schema&gt;</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">dataNode ：字符串，分片节点名称，多个以&quot;，&quot;号分隔</span><br><span class="line"></span><br><span class="line">checkSQLschema ：布尔类型，当该值设置为 true 时，如果我们执行语句**select * from TESTDB.travelrecord;**则MyCat 会把语句修改为**select * from travelrecord;**。即把表示schema的字符去掉，避免发送到后端数据库执行时报**（ERROR 1146 (42S02): Table &apos;testdb.travelrecord&apos; doesn&apos;t exist）。** 不过，即使设置该值为 true ，如果语句所带的是并非是schema指定的名字，例如：**select * from db1.travelrecord;** 那么MyCat并不会删除db1这个字段，如果没有定义该库的话则会报错，所以在提供SQL语句的最好是不带这个字段。</span><br><span class="line"></span><br><span class="line">sqlMaxLimit ：int 类型，表示每条执行的SQL语句，如果没有加上limit语句，MyCat也会自动的加上所对应的值。例如设置值为100，执行**select * from TESTDB.travelrecord;**的效果为和执行**select * from TESTDB.travelrecord limit 100;**相同。 设置该值的话，MyCat默认会把查询到的信息全部都展示出来，造成过多的输出。所以，在正常使用中，还是建议加上一个值，用于减少过多的数据返回。 当然SQL语句中也显式的指定limit的大小，不受该属性的约束。 需要注意的是，如果运行的 schema为非拆分库的，那么该属性不会生效。需要手动添加limit语句。</span><br><span class="line"></span><br><span class="line">table 标签</span><br><span class="line"></span><br><span class="line">该标签属于 schema 的子标签，用于定义了MyCat中的逻辑表，所有需要拆分的表都需要在这个标签中定义。</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">name：定义逻辑表的表名，这个名字就如同我在数据库中执行create table命令指定的名字一样，同个schema标签中定义的名字必须唯一。</span><br><span class="line"></span><br><span class="line">dataNode：定义这个逻辑表所属的dataNode, 该属性的值需要和dataNode标签中name 属性的值相互对应。</span><br><span class="line"></span><br><span class="line">rule：该属性用于指定逻辑表要使用的规则名字，规则名字在rule.xml中定义，必须与tableRule标签中name属性属性值一一对应</span><br><span class="line"></span><br><span class="line">ruleRequired ：该属性用于指定表是否绑定分片规则，如果配置为true，但没有配置具体rule的话 ，程序会报错</span><br><span class="line"></span><br><span class="line">type：该属性定义了逻辑表的类型，目前逻辑表只有&quot;全局表&quot;和&quot;普通表&quot;两种类型。对应的配置：</span><br><span class="line">全局表：global</span><br><span class="line">普通表：不指定该值为globla的所有表</span><br><span class="line"></span><br><span class="line">needAddLimit ：指定表是否需要自动的在每个语句后面加上limit限制，这个属性默认为 true</span><br><span class="line"></span><br><span class="line">primaryKey ：该逻辑表对应真实表的主键，例如：分片的规则是使用非主键进行分片的，那么在使用主键查询的时候，就会发送查询语句到所有配置的 DN上，如果使用该属性配置真实表的主键。难么MyCat会缓存主键与具体DN 的信息，那么再次使用非主键进行查询的时候就不会进行广播式的查询，就会直接发送语句给具体的 DN，但是尽管配置该属性，如果缓存并没有命中的话，还是会发送语句给具体的 DN，来获得数据。</span><br><span class="line"></span><br><span class="line">autoIncrement ：mysql对非自增长主键，使用last_insert_id()是不会返回结果的，只会返回0。所以，只有定义了自增长主键的表才可以用last_insert_id()返回主键值。 mycat目前提供了自增长主键功能，但是如果对应的 mysql节点上数据表，没有定义auto_increment，那么在mycat层调用last_insert_id()也是不会返回结果的。 由于insert操作的时候没有带入分片键，mycat会先取下这个表对应的全局序列，然后赋值给分片键。这样才能正常的插入到数据库中，最后使用last_insert_id()才会返回插入的分片键值。 如果要使用这个功能最好配合使用数据库模式的全局序列。</span><br><span class="line">使用autoIncrement=&quot;true&quot; 指定这个表有使用自增长主键，这样mycat才会不抛出分片键找不到的异常。</span><br><span class="line">使用 autoIncrement=&quot;false&quot; 来禁用这个功能，当然你也可以直接删除掉这个属性。默认就是禁用的。</span><br><span class="line"></span><br><span class="line">subTables ：配置分表规则，并且在分表条件下，只能配置一个 dataNode，并且分表条件下不支持各种条件的 join 语句。配置实例如： subTables=&quot;t_order$1-2,t_order3&quot; ，</span><br><span class="line">分库模式下是：insert into table（xxx）values(1,name);</span><br><span class="line">router：&#123;</span><br><span class="line">node1：insert into table（xxx）values(1,name) ,datanode1,</span><br><span class="line">node2：insert into table（xxx）values(2,name) ,datanode2,</span><br><span class="line">node3：insert into table（xxx）values(3,name) ,datanode3,</span><br><span class="line">&#125;，</span><br><span class="line">分表模式是： insert into table（xxx）values(1,name);</span><br><span class="line">router：&#123;</span><br><span class="line">node1：insert into table1（xxx）values(1,name) ,datanode1,</span><br><span class="line">node2：insert into table2（xxx）values(2,name) ,datanode1,</span><br><span class="line">node3：insert into table3（xxx）values(3,name) ,datanode1,</span><br><span class="line">&#125;，</span><br><span class="line"></span><br><span class="line">childTable 标签</span><br><span class="line"></span><br><span class="line">该标签属于 table 的子标签，该标签用于定义E-R分片的子表，通过标签上的属性与父表进行关联。</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">name ：定义子表的表名</span><br><span class="line"></span><br><span class="line">joinKey ：插入子表的时候会使用这个列的值查找父表存储的数据节点。</span><br><span class="line"></span><br><span class="line">parentKey ：属性指定的值一般为与父表建立关联关系的列名。</span><br><span class="line"></span><br><span class="line">primaryKey ：该逻辑表对应真实表的主键，例如：分片的规则是使用非主键进行分片的，那么在使用主键查询的时候，就会发送查询语句到所有配置的 DN上，如果使用该属性配置真实表的主键。难么MyCat会缓存主键与具体DN 的信息，那么再次使用非主键进行查询的时候就不会进行广播式的查询，就会直接发送语句给具体的 DN，但是尽管配置该属性，如果缓存并没有命中的话，还是会发送语句给具体的 DN，来获得数据。</span><br><span class="line"></span><br><span class="line">needAddLimit ：指定表是否需要自动的在每个语句后面加上limit限制，这个属性默认为 true</span><br><span class="line"></span><br><span class="line">dataNode 标签</span><br><span class="line"></span><br><span class="line">dataNode 标签定义了 MyCat中的数据节点，也就是我们通常说所的数据分片。一个dataNode 标签就是一个独立的数据分片，比如我们要创建使用名字为lch3307数据库实例上的db1物理数据库，这就组成一个数据分片，最后，我们使用名字dn1标识这个分片，实例配置如下：</span><br><span class="line"></span><br><span class="line">&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;lch3307&quot; database=&quot;db1&quot;&gt;&lt;/dataNode&gt;</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">name ：定义数据节点的名字，这个名字需要是唯一的，我们需要在 table标签上应用这个名字，来建立表与分片对应的关系。</span><br><span class="line"></span><br><span class="line">dataHost ：该属性用于定义该分片属于哪个数据库实例的，属性值是引用 dataHost标签上定义的name属性</span><br><span class="line"></span><br><span class="line">database：该属性用于定义该分片属性哪个具体数据库实例上的具体库，因为这里使用两个纬度来定义分片，就是：实例+具体的库。因为每个库上建立的表和表结构是一样的。所以这样做就可以轻松的对表进行水平拆分。</span><br><span class="line"></span><br><span class="line">dataHost标签</span><br><span class="line"></span><br><span class="line">该标签在mycat逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语。</span><br><span class="line"></span><br><span class="line">&lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;</span><br><span class="line">writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot;&gt;</span><br><span class="line">&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;</span><br><span class="line">&lt;!-- 可以有多个写入主机 --&gt;</span><br><span class="line">&lt;!-- 第一个主机 --&gt;</span><br><span class="line">&lt;writeHost host=&quot;hostM1&quot; url=&quot;localhost:3306&quot; user=&quot;root&quot; password=&quot;123456&quot;&gt;</span><br><span class="line">&lt;!-- balance=3 所有读请求使用该服务器执行，可以有多个读主机 --&gt;</span><br><span class="line">&lt;readHost host=&quot;hostS1&quot; url=&quot;localhost:3306&quot; user=&quot;root&quot; password=&quot;123456&quot; /&gt;</span><br><span class="line">&lt;/writeHost&gt;</span><br><span class="line">&lt;!-- 第二个主机 --&gt;</span><br><span class="line">&lt;writeHost host=&quot;hostM2&quot; url=&quot;localhost:3316&quot; user=&quot;root&quot; password=&quot;123456&quot;/&gt;</span><br><span class="line">&lt;/dataHost&gt;</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">name ：唯一标识dataHost 标签</span><br><span class="line">maxCon：指定每个读写实例连接池的最大连接。也就是说，标签内嵌套的 writeHost、readHost标签都会使用这个属性的值来实例化出连接池的最大连接数</span><br><span class="line">minCon ：指定每个读写实例连接池的最小连接，初始化连接池的大小</span><br><span class="line">balance：负载均衡类型，目前的取值有4 种：</span><br><span class="line">balance=&quot;0&quot;, 不开启读写分离机制，所有读操作都发送到当前可用的 writeHost上。</span><br><span class="line">balance=&quot;1&quot;，全部的readHost与 stand by writeHost 参与 select语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且 M1与 M2互为主备)，正常情况下，M2,S1,S2都参与 select语句的负载均衡。</span><br><span class="line">balance=&quot;2&quot;，所有读操作都随机的在writeHost、readhost上分发。</span><br><span class="line">balance=&quot;3&quot;，所有读请求随机的分发到wiriterHost对应的readhost执行，writerHost 不负担读压力</span><br><span class="line">dbType ：指定后端连接的数据库类型，目前支持二进制的mysql协议，还有其他使用 JDBC连接的数据库。例如：mongodb、oracle、spark等。</span><br><span class="line">dbDriver：指定连接后端数据库使用的Driver，目前可选的值有native和 JDBC。使用native的话，因为这个值执行的是二进制的mysql协议，所以可以使用mysql、maridb 和 postgresql（1.6版本），其他类型的数据库则需要使用 JDBC驱动来支持，如果使用JDBC的话需要将符合 JDBC 4标准的驱动JAR包放到 MYCAT\lib目录下，并检查驱动JAR包中包括如下目录结构的文件：META-INF\services\java.sql.Driver，在这个文件内写上具体的Driver 类名，例如：com.mysql.jdbc.Driver</span><br><span class="line">switchType：主从数据库切换类型，目前的取值有4种：</span><br><span class="line">-1 表示不自动切换</span><br><span class="line">1 默认值，自动切换</span><br><span class="line">2 基于MySQL主从同步的状态决定是否切换心跳语句为 show slave status</span><br><span class="line">3 基于MySQL galary cluster的切换机制（适合集群）心跳语句为 show status like &apos;wsrep%&apos;</span><br><span class="line">tempReadHostAvailable：如果配置了这个属性writeHost 下面的readHost仍旧可用，默认0 可配置（0、1）</span><br><span class="line"></span><br><span class="line">heartbeat标签</span><br><span class="line"></span><br><span class="line">这个标签属于dataHost的子标签内指明用于和后端数据库进行心跳检查的语句。例如,MYSQL可以使用select user()，Oracle可以使用select 1 from dual等。这个标签还有一个connectionInitSql 属性，主要是当使用Oracla数据库时，需要执行的初始化SQL语句就这个放到这里面来。例如：alter session set nls_date_format=&apos;yyyy-mm-dd hh24:mi:ss&apos; ，示例代码：</span><br><span class="line">&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;</span><br><span class="line"></span><br><span class="line">writeHost 和 readHost 标签</span><br><span class="line"></span><br><span class="line">这两个标签都属于dataHost的子标签，用于指定后端数据库的相关配置给 mycat，用于实例化后端连接池。唯一不同的是，writeHost指定写实例、readHost指定读实例，组着这些读写实例来满足系统的要求。在一个dataHost内可以定义多个writeHost和readHost。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。另一方面，由于这个writeHost宕机系统会自动的检测到，并切换到备用的writeHost上去。</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">host：用于标识不同实例，一般writeHost我们使用*M1，readHost我们用*S1</span><br><span class="line">url：后端实例连接地址，如果是使用native 的dbDriver，则一般为address:port 这种形式。用 JDBC或其他的</span><br><span class="line">dbDriver，则需要特殊指定。当使用JDBC 时则可以这么写：jdbc:mysql://localhost:3306/</span><br><span class="line"></span><br><span class="line">user：后端存储实例需要的用户名字</span><br><span class="line">password ：后端存储实例需要的密码</span><br><span class="line">weight ：权重，配置在readhost 中作为读节点的权重</span><br><span class="line">usingDecrypt ：是否对密码加密，默认否=0， 如需要开启配置=1，同时使用加密程序对密码加密，加密命令为：</span><br><span class="line"># java -cp Mycat-server-1.6-RELEASE.jar io.mycat.util.DecryptUtil 1:host:user:password</span><br><span class="line"></span><br><span class="line">其中 Mycat-server-1.6-RELEASE.jar 位于 mycat/lib 目录中，1:host:user:password，其中 1 表示 db端加密标识</span><br></pre></td></tr></table></figure><ol start="2"><li>server.xml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">server.xml 几乎保存了所有mycat需要的系统配置信息，包括 mycat 用户管理、DML权限管理等，其在代码内直接的映射类为SystemConfig 类。</span><br><span class="line"></span><br><span class="line">user 标签</span><br><span class="line"></span><br><span class="line">该标签主要用于定义登录 mycat的用户和权限。例如，我定义了一个用户，用户名为test、密码也为test，可访问的schema也只有TESTDB一个，示例代码如下：</span><br><span class="line"></span><br><span class="line">&lt;!-- 用户名称 --&gt;</span><br><span class="line">&lt;user name=&quot;test&quot;&gt;</span><br><span class="line">&lt;!-- 账户信息 --&gt;</span><br><span class="line">&lt;!-- 用户密码 --&gt;</span><br><span class="line">&lt;property name=&quot;password&quot;&gt;test&lt;/property&gt;</span><br><span class="line">&lt;!-- 逻辑数据库名称，存在多个则使用&quot;，&quot;号分隔 --&gt;</span><br><span class="line">&lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt;</span><br><span class="line">&lt;!-- 只读 --&gt;</span><br><span class="line">&lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;</span><br><span class="line">&lt;!-- 连接服务降级的基准连接数量 --&gt;</span><br><span class="line">&lt;property name=&quot;benchmark&quot;&gt;11111&lt;/property&gt;</span><br><span class="line">&lt;!-- 是否对密码加密 --&gt;</span><br><span class="line">&lt;property name=&quot;usingDecrypt&quot;&gt;1&lt;/property&gt;</span><br><span class="line">&lt;!-- 精细化DML权限控制 --&gt;</span><br><span class="line">&lt;privileges check=&quot;false&quot;&gt;</span><br><span class="line">&lt;schema name=&quot;TESTDB&quot; dml=&quot;0010&quot; showTables=&quot;custome/mysql&quot;&gt;</span><br><span class="line">&lt;table name=&quot;tbl_user&quot; dml=&quot;0110&quot;&gt;&lt;/table&gt;</span><br><span class="line">&lt;table name=&quot;tbl_dynamic&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt;</span><br><span class="line">&lt;/schema&gt;</span><br><span class="line">&lt;/privileges&gt;</span><br><span class="line">&lt;/user&gt;</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">Benchmark：mycat 连接服务降级处理，当前端的整体 connection 数达到基准值时，对来自该账户的请求开始拒绝连接，0 或不设表示不限制</span><br><span class="line">usingDecrypt：是否对密码加密默认0 否 如需要开启配置1，同时使用加密程序对密码加密，加密命令为：</span><br><span class="line"># java -cp Mycat-server-1.6-RELEASE.jar io.mycat.util.DecryptUtil 0:user:password</span><br><span class="line"></span><br><span class="line">其中 Mycat-server-1.6-RELEASE.jar 位于 mycat/lib 目录中，0:user:password，其中 0 表示 前端加密标识</span><br><span class="line"></span><br><span class="line">privileges 标签</span><br><span class="line"></span><br><span class="line">对用户的 schema 及 下级的 table 进行精细化的 DML 权限控制，privileges 节点中的 check 属性是用于标识是否开启 DML 权限检查， 默认false 标识不检查，当然 privileges 节点不配置，等同 check=false, 由于Mycat一个用户的schemas 属性可配置多个 schema ，所以 privileges 的下级节点 schema 节点同样可配置多个，对多库多表进行细粒度的DML 权限控制，在 schema 及 table 上设置 dml 字符串的规则时按照如下规则设置的，示例如下：</span><br><span class="line"></span><br><span class="line">操作                              DML权限示例                  说明</span><br><span class="line">insert,update,select,delete       0000             禁止增加、更新、查询和删除</span><br><span class="line">insert,update,select,delete       0010          禁止增加、更新和删除，可以查询</span><br><span class="line">insert,update,select,delete       1110          禁止删除，可以创建、更新和查询</span><br><span class="line"></span><br><span class="line">如果设置了 schema 的 DML，而没有设置 table 的 DML，则自动继承 schema 的 DML 属性</span><br></pre></td></tr></table></figure><ol start="3"><li>rule.xml</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">rule.xml 配置文件定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，</span><br><span class="line"></span><br><span class="line">或者对表使用相同的算法但具体的参数不同。</span><br><span class="line">tableRule 标签</span><br><span class="line">该标签用于定义表的拆分规则，示例代码如下：</span><br><span class="line"></span><br><span class="line">&lt;tableRule name=&quot;rule1&quot;&gt;</span><br><span class="line">&lt;rule&gt;</span><br><span class="line">&lt;columns&gt;id&lt;/columns&gt;</span><br><span class="line">&lt;algorithm&gt;func1&lt;/algorithm&gt;</span><br><span class="line">&lt;/rule&gt;</span><br><span class="line">&lt;/tableRule&gt;</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">name：指定唯一的表拆分规则的名称</span><br><span class="line">columns：指定要拆分的列名字</span><br><span class="line">algorithm：使用 function 标签中的 name 属性，用于连接表规则和具体的路由算法，多个表规则可以连接到一个路由算法。</span><br><span class="line">function 标签</span><br><span class="line"></span><br><span class="line">该标签用于定义具体的拆分路由算法，示例代码如下：</span><br><span class="line"></span><br><span class="line">&lt;function name=&quot;hash-int&quot; class=&quot;org.opencloudb.route.function.PartitionByFileMap&quot;&gt;</span><br><span class="line">&lt;property name=&quot;mapFile&quot;&gt;partition-hash-int.txt&lt;/property&gt;</span><br><span class="line">&lt;/function&gt;</span><br><span class="line"></span><br><span class="line">相关属性</span><br><span class="line">name：指定算法的名称，在文件中唯一</span><br><span class="line">class：指定对应具体的分片算法的具体类</span><br><span class="line">property：具体算法的必须参数</span><br></pre></td></tr></table></figure><ol start="4"><li>Mycat 分片规则<br>1）枚举分片<br>2）范围分片<br>3）取模分片<br>4）ER关系表分片<br>5）固定 hash 分片<br>6）范围取模分片<br>7）应用指定分片<br>8）ASCII 取模范围分片<br>9）取模范围分片<br>10）自然月分片<br>11）日期（天）分片<br>12）单月小时分片<br>13）日期范围 hash 分片<br>14）一致性hash分片</li></ol><p>详解参考地址：<a href="https://www.cnblogs.com/li3807/category/1165516.html" target="_blank" rel="noopener">https://www.cnblogs.com/li3807/category/1165516.html</a></p><h3 id="Mycat启动"><a href="#Mycat启动" class="headerlink" title="Mycat启动"></a>Mycat启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./mycat console</span><br><span class="line">或者</span><br><span class="line">./mycat start</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;按照上一章步骤搭建完mysql的集群，且验证主从复制没有问题，本篇来安装mycat&lt;/p&gt;
&lt;p&gt;先理解下面几个概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;垂直分表：将一个表按照字段分成多表，每个表存储其中一部分字段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;垂直分库：是指按照业务将
      
    
    </summary>
    
      <category term="Mycat" scheme="http://macintosh-c.coding.me/categories/Mycat/"/>
    
    
      <category term="mycat" scheme="http://macintosh-c.coding.me/tags/mycat/"/>
    
  </entry>
  
  <entry>
    <title>Mysql锁表解决</title>
    <link href="http://macintosh-c.coding.me/2021/06/25/Databases/mysql/mysql%E9%94%81%E8%A1%A8%E8%A7%A3%E5%86%B3/"/>
    <id>http://macintosh-c.coding.me/2021/06/25/Databases/mysql/mysql锁表解决/</id>
    <published>2021-06-25T02:49:36.000Z</published>
    <updated>2021-06-25T05:50:34.451Z</updated>
    
    <content type="html"><![CDATA[<p>问题：<br>ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction</p><p>解决方式如下：</p><p>1、先查看数据库的事务隔离级别：</p><p>select @@tx_isoloation;<br>REPEATABLE-READ // MySQL默认的事务隔离级别就是REPEATABLE-READ</p><p>2、然后查看当前数据库的线程情况：</p><p>SHOW FULL PROCESSLIST;</p><p>没有看到正在执行的很慢SQL记录线程，再去查看innodb的事务表INNODB_TRX，看下里面是否有正在锁定的事务线程，看看ID是否在show full processlist里面的sleep线程中，如果是，就证明这个sleep的线程事务一直没有commit或者rollback而是卡住了，我们需要手动kill掉。</p><p>SELECT * FROM information_schema.INNODB_TRX;</p><p>trx _mysql_thread_id  为 616694</p><p>其他相关表：<br>information_schema.innodb_trx表：查询当前运行的所有事务<br>information_schema.innodb_locks表：查询当前出现的锁<br>information_schema.innodb_lock_waits表：查询锁等待的对应关系<br>sys.schema_table_lock_waits：查询造成阻塞的线程ID</p><p>3、发现有id为616694的sql，需要手动kill掉<br>KILL 616694;<br>kill之后，再去执行上面的sql语句，就可以执行成功了。</p><p>注意：MySQL是自动提交事务的（即：autocommit=1），可以使用 show variables like ‘autocommit’ 或者 select @@autocommit 查看当前数据库是否为自动提交事务；若autocommit的值不是1还可以使用set global autocommit = 1 将自动提交设置为开启。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;问题：&lt;br&gt;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction&lt;/p&gt;
&lt;p&gt;解决方式如下：&lt;/p&gt;
&lt;p&gt;1、先查看数据库的事务隔离级别：&lt;/p&gt;
&lt;p&gt;select @@
      
    
    </summary>
    
      <category term="Mysql" scheme="http://macintosh-c.coding.me/categories/Mysql/"/>
    
    
      <category term="Mysql" scheme="http://macintosh-c.coding.me/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>一、mysql集群搭建</title>
    <link href="http://macintosh-c.coding.me/2021/06/25/Databases/mycat/1.mysql%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://macintosh-c.coding.me/2021/06/25/Databases/mycat/1.mysql集群搭建/</id>
    <published>2021-06-25T01:49:36.000Z</published>
    <updated>2021-06-25T09:24:24.523Z</updated>
    
    <content type="html"><![CDATA[<p>最近项目变更，为适应支撑更大的场景需求，需要在db层面做分库分表来提升系统的性能，同时需要做大量的数据迁移工作，量级过亿。于是，把mysql的搭建，主从，读写分离以及基于mycat分库分表又系统的实践了一遍。纸上得来终觉浅，绝知此事要躬行。收获满满。</p><h3 id="Mysql集群搭建"><a href="#Mysql集群搭建" class="headerlink" title="Mysql集群搭建"></a>Mysql集群搭建</h3><p>由于资源有限，使用Vmware起了3台虚拟机，每台2core4G，Mac本勉强可以支撑住，同时准备搭建一个3主3从的集群，所有需要在单节点搭建2个mysql实例，分别使用不同的端口号，做一主一从。</p><h5 id="单节点安装多mysql实例"><a href="#单节点安装多mysql实例" class="headerlink" title="单节点安装多mysql实例"></a>单节点安装多mysql实例</h5><p>MySQL多实例部署主要有以下两种方式：</p><p>1.使用官方自带的mysqld_multi来配置管理，特点是使用同一份MySQL配置文件，这种方式属于集中式管理，管理起来较为方便；<br>2.使用单独的MySQL配置文件来单独配置实例，这种方式逻辑简单，数据库之间没有关联。</p><p>因为本人使用的是第二种，第一种就不详加说明了，可参考：<a href="https://www.cnblogs.com/lijiaman/p/12587630.html" target="_blank" rel="noopener">https://www.cnblogs.com/lijiaman/p/12587630.html</a></p><p>过程如下：</p><ol><li>在安装MySQL之前，需要卸载服务器自带的MySQL包和MySQL数据库分支mariadb的包</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa |grep mariadb</span><br><span class="line">rpm -e mariadb-libs-5.5.56-2.el7.x86_64 --nodeps</span><br></pre></td></tr></table></figure><ol start="2"><li>创建用户和用户组</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">groupadd mysql</span><br><span class="line">useradd -r -g mysql -s /bin/false mysql</span><br></pre></td></tr></table></figure><ol start="3"><li>解压安装包</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/</span><br><span class="line">tar -xzvf /opt/package/mysql-5.7.31-linux-glibc2.12-x86_64.tar.gz </span><br><span class="line">mv mysql-5.7.31-linux-glibc2.12-x86_64/ mysql</span><br></pre></td></tr></table></figure><ol start="4"><li>创建数据文件存放路径</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/data/mysql/&#123;3306,3307&#125;/data</span><br><span class="line">cd /opt/data/mysql/</span><br><span class="line">chown -R mysql:mysql /opt/data/mysql/</span><br><span class="line">cd 3306/</span><br><span class="line">mkdir run</span><br><span class="line">mkdir logs</span><br><span class="line">mkdir tmp</span><br></pre></td></tr></table></figure><ol start="5"><li>创建MySQL参数配置文件</li></ol><p>此处贴一份本人使用完整的配置文件如下,和上面创建的文件路径要匹配,my.cnf文件/opt/data/mysql/3306,3307端口按照其路径配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">[mysql]</span><br><span class="line"># CLIENT #</span><br><span class="line">port                           = 3306</span><br><span class="line">socket                         = /tmp/mysql_3306.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line"># GENERAL #</span><br><span class="line">server-id                      = 1</span><br><span class="line">port                           = 3306</span><br><span class="line">user                           = mysql</span><br><span class="line">default-storage-engine         = InnoDB</span><br><span class="line">socket                         = /tmp/mysql_3306.sock</span><br><span class="line">pid-file                       = /opt/data/mysql/3306/run/mysqld.pid</span><br><span class="line">default_authentication_plugin  = mysql_native_password</span><br><span class="line">basedir                        = /usr/local/mysql/</span><br><span class="line">datadir                        = /opt/data/mysql/3306/data</span><br><span class="line">transaction_isolation = READ-COMMITTED</span><br><span class="line">tmpdir                         = /opt/data/mysql/3306/tmp</span><br><span class="line">bind-address                   = 0.0.0.0</span><br><span class="line">slave-skip-errors              = all</span><br><span class="line">default-time_zone              = &apos;+0:00&apos;</span><br><span class="line">character-set-server           = utf8mb4</span><br><span class="line">collation-server               = utf8mb4_unicode_ci</span><br><span class="line">tls_version                    = TLSv1.2</span><br><span class="line">secure_file_priv               = /tmp/mysql-files</span><br><span class="line">net_read_timeout               = 60</span><br><span class="line">interactive_timeout=31536000</span><br><span class="line">wait_timeout=31536000</span><br><span class="line"></span><br><span class="line"># BINARY LOGGING #</span><br><span class="line">log-bin                        = mysql-bin</span><br><span class="line">relay-log                      = relay-bin</span><br><span class="line">sync_binlog                    = 1</span><br><span class="line">binlog_format                  = MIXED</span><br><span class="line">relay_log_purge                = 0</span><br><span class="line">expire_logs_days               = 7</span><br><span class="line"></span><br><span class="line"># slave</span><br><span class="line">slave-parallel-type=LOGICAL_CLOCK</span><br><span class="line">slave-parallel-workers=16</span><br><span class="line">master_info_repository=TABLE</span><br><span class="line">relay_log_info_repository=TABLE</span><br><span class="line">relay_log_recovery=ON</span><br><span class="line"></span><br><span class="line"># GTID #</span><br><span class="line">gtid-mode = ON</span><br><span class="line">enforce-gtid-consistency = ON</span><br><span class="line"></span><br><span class="line"># replication #</span><br><span class="line">#rpl_semi_sync_master_enabled    = 1</span><br><span class="line">#rpl_semi_sync_master_wait_no_slave = On</span><br><span class="line"></span><br><span class="line"># MyISAM #</span><br><span class="line"># key-buffer-size                = 32M</span><br><span class="line"># myisam-recover                 = FORCE,BACKUP</span><br><span class="line"></span><br><span class="line"># SAFETY #</span><br><span class="line">max-allowed-packet             = 256M</span><br><span class="line">max-connect-errors             = 1000000</span><br><span class="line">skip-name-resolve</span><br><span class="line">sql-mode                       = NO_ENGINE_SUBSTITUTION,NO_AUTO_CREATE_USER</span><br><span class="line">sysdate-is-now                 = 1</span><br><span class="line">innodb-strict-mode             = 1</span><br><span class="line"></span><br><span class="line"># CACHES AND LIMITS #</span><br><span class="line">max-connections                = 65535</span><br><span class="line">tmp-table-size                 = 32M</span><br><span class="line">max-heap-table-size            = 32M</span><br><span class="line">query-cache-type               = 0</span><br><span class="line">query-cache-size               = 0</span><br><span class="line">thread-cache-size              = 50</span><br><span class="line">open-files-limit               = 65535</span><br><span class="line">table-definition-cache         = 1024</span><br><span class="line">table-open-cache               = 2048</span><br><span class="line"></span><br><span class="line"># INNODB #</span><br><span class="line">innodb-flush-method            = O_DIRECT</span><br><span class="line">innodb-log-files-in-group      = 2</span><br><span class="line">innodb-log-file-size           = 768M</span><br><span class="line">innodb-flush-log-at-trx-commit = 1</span><br><span class="line">innodb-file-per-table          = 1</span><br><span class="line">innodb-buffer-pool-size        = 128M</span><br><span class="line"></span><br><span class="line"># LOGGING #</span><br><span class="line">log-error                      = /opt/data/mysql/3306/logs/mysqld.log</span><br><span class="line">slow-query-log                 = 1</span><br><span class="line">slow-query-log-file            = /opt/data/mysql/3306/logs/mysqld-slow.log</span><br><span class="line">log-queries-not-using-indexes  = OFF</span><br><span class="line">long_query_time                = 30</span><br><span class="line"></span><br><span class="line">[mysqldump]</span><br><span class="line">max-allowed-packet             = 256M</span><br></pre></td></tr></table></figure><p>部分参数说明：（ 在后续的过程中碰到的参数，这里提前说明下）<br>1). server-id 集群的配置，每个集群里所有实例需要不一样</p><p>2). secure_file_priv参数用于限制LOAD DATA, SELECT …OUTFILE, LOAD_FILE()传到哪个指定目录。否则会报：ERROR 1290 (HY000): The MySQL server is running with the –secure-file-priv option so it cannot execute this statement。<br>可通过：show global variables like ‘%secure_file_priv%’;查看<br>secure_file_priv 为 NULL 时，表示限制mysqld不允许导入或导出。<br>secure_file_priv 为 /tmp 时，表示限制mysqld只能在/tmp目录中执行导入导出，其他目录不能执行。<br>secure_file_priv 没有值时，表示不限制mysqld在任意目录的导入导出。</p><p>3). log-bin 打开binlog，主从必须要打开</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">只查看第一个binlog文件的内容:show binlog events;</span><br><span class="line">查看指定binlog文件的内容:show binlog events in &apos;mysql-bin.000002&apos;;</span><br><span class="line">查看当前正在写入的binlog文件:show master status\G;</span><br><span class="line">获取binlog文件列表:show binary logs;</span><br></pre></td></tr></table></figure><p>4). binlog_format binlog的日记模式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Statement level（默认）</span><br><span class="line">每一条被修改数据的sql都会记录到master的bin-log中，slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql再次执行</span><br><span class="line">优点：不需要记录每一行的数据变化，减少bin-log日志量，节约磁盘IO，提高新能</span><br><span class="line">缺点：容易出现主从复制不一致</span><br><span class="line"></span><br><span class="line">Row level</span><br><span class="line">日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。</span><br><span class="line">优点：能清楚的记录每一行数据修改的细节</span><br><span class="line">缺点：数据量太大</span><br><span class="line"></span><br><span class="line">Mixed（混合模式）</span><br><span class="line">以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。</span><br></pre></td></tr></table></figure></p><p>5). sync_binlog</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sync_binlog=0</span><br><span class="line">当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。这个是性能最好的。</span><br><span class="line"></span><br><span class="line">sync_binlog=1</span><br><span class="line">当每进行1次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。</span><br><span class="line"></span><br><span class="line">sync_binlog=n</span><br><span class="line">当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。</span><br><span class="line"></span><br><span class="line">注：大多数情况下，对数据的一致性并没有很严格的要求，所以并不会把 sync_binlog 配置成 1. 为了追求高并发，提升性能，可以设置为 100 或直接用 0，而对于支付服务这样的应用，还是比较推荐 sync_binlog = 1.</span><br></pre></td></tr></table></figure><p>6). lower_case_table_names 区分大小写设置<br>  lower_case_table_names： 此参数不可以动态修改，必须重启数据库<br>  lower_case_table_names = 1  表名存储在磁盘是小写的，但是比较的时候是不区分大小写<br>  lower_case_table_names=0  表名存储为给定的大小和比较是区分大小写的<br>  lower_case_table_names=2, 表名存储为给定的大小写但是比较的时候是小写的</p><p>可通过：show variables like ‘lower_case_table_names’;查看</p><blockquote><blockquote><p>补充：关于mysql大小写<br>    linux下：<br>  数据库名与表名是严格区分大小写的；<br>  表的别名是严格区分大小写的；<br>  列名与列的别名在所有的情况下均是忽略大小写的；<br>  变量名也是严格区分大小写的；<br>  windows下：<br>  都不区分大小写<br>  Mac OS下（非UFS卷）：<br>  都不区分大小写</p></blockquote></blockquote><p>7). gtid-mode 全局事务标识：global transaction identifiers。</p><p>从MySQL 5.6.5 开始新增了一种基于 GTID 的复制方式。通过 GTID 保证了每个在主库上提交的事务在集群中有一个唯一的ID。这种方式强化了数据库的主备一致性，故障恢复以及容错能力。</p><p>GTID (Global Transaction ID)是全局事务ID,当在主库上提交事务或者被从库应用时，可以定位和追踪每一个事务，对DBA来说意义就很大了，我们可以适当的解放出来，不用手工去可以找偏移量的值了，而是通过CHANGE MASTER TO MASTER_HOST=’xxx’, MASTER_AUTO_POSITION=1的即可方便的搭建从库，在故障修复中也可以采用MASTER_AUTO_POSITION=‘X’的方式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gtid-mode=on                        --启用gtid类型，否则就是普通的复制架构</span><br><span class="line">enforce-gtid-consistency=true       --强制GTID的一致性</span><br><span class="line">log-slave-updates=1                 --强制slave记录二进制日志</span><br></pre></td></tr></table></figure><p>可通过：show variables like ‘%gtid%’;查看</p><p>附详解一份：<a href="https://www.jianshu.com/p/f74ddf4f4372" target="_blank" rel="noopener">https://www.jianshu.com/p/f74ddf4f4372</a></p><ol start="6"><li>初始化数据库<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mysql/bin/mysqld --defaults-file=/opt/data/mysql/3306/my.cnf --initialize --basedir=/usr/local/mysql/ --datadir=/opt/data/mysql/3306/data</span><br></pre></td></tr></table></figure></li></ol><p>可在logs里查看到初始化的mysql密码，首次登录需要。</p><ol start="7"><li><p>设置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@masterdb mysql]# vim /etc/profile</span><br><span class="line"># 在文件末尾添加下面信息</span><br><span class="line">export PATH=/usr/local/mysql/bin:$PATH</span><br><span class="line">#使环境变量生效</span><br><span class="line">[root@masterdb mysql]# source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>启动数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 经过测试，mysql在初始化的时候新生成的部分文件权限为root,所以最好在启动之前重新将datadir路径授权给mysql</span><br><span class="line">[root@masterdb mysql]# chown -R mysql:mysql /opt/data/mysql</span><br><span class="line"></span><br><span class="line"># 启动MySQL数据库实例</span><br><span class="line">[root@masterdb ~]# nohup /usr/local/mysql/bin/mysqld --defaults-file=/opt/data/mysql/3306/my.cnf --user=mysql &amp;</span><br></pre></td></tr></table></figure></li><li><p>访问多实例数据库<br>mysql -S /tmp/mysql_3306.sock -p<br>修改数据库root@localhost密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter user  root@localhost identified by &apos;123456&apos;;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></li><li><p>本地无法连接远程服务器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select host from user where user = &apos;root&apos;;</span><br><span class="line">update user set host = &apos;%&apos; where user = &apos;root&apos;;</span><br><span class="line">重启数据库</span><br></pre></td></tr></table></figure></li><li><p>主从配置</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">master上创建用于主从复制的账户：</span><br><span class="line">GRANT REPLICATION SLAVE ON *.* TO &apos;slave&apos;@&apos;%&apos; IDENTIFIED BY &apos;123123&apos;;</span><br><span class="line"></span><br><span class="line">slave节点创建主节点复制的链接</span><br><span class="line">change master to master_host=&apos;192.168.181.142&apos;,MASTER_PORT=3306,master_user=&apos;slave&apos;,master_password=&apos;123123&apos;,MASTER_AUTO_POSITION=1;</span><br><span class="line">start slave;</span><br><span class="line">show slave status\G;</span><br></pre></td></tr></table></figure><p>按如下关系配置最终集群资源，同时创建测试库表，验证同步是否ok</p><p>192.168.181.141   3306(master)   对应  192.168.181.142  3307(slave)<br>192.168.181.142   3306(master)   对应  192.168.181.143  3307(slave)<br>192.168.181.143   3306(master)   对应  192.168.181.141  3307(slave)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近项目变更，为适应支撑更大的场景需求，需要在db层面做分库分表来提升系统的性能，同时需要做大量的数据迁移工作，量级过亿。于是，把mysql的搭建，主从，读写分离以及基于mycat分库分表又系统的实践了一遍。纸上得来终觉浅，绝知此事要躬行。收获满满。&lt;/p&gt;
&lt;h3 id=
      
    
    </summary>
    
      <category term="Mycat" scheme="http://macintosh-c.coding.me/categories/Mycat/"/>
    
    
      <category term="mycat" scheme="http://macintosh-c.coding.me/tags/mycat/"/>
    
  </entry>
  
  <entry>
    <title>Redis-Sentinel</title>
    <link href="http://macintosh-c.coding.me/2021/05/31/Databases/Redis/redis-Sentinel/"/>
    <id>http://macintosh-c.coding.me/2021/05/31/Databases/Redis/redis-Sentinel/</id>
    <published>2021-05-31T04:20:29.000Z</published>
    <updated>2021-05-31T09:53:47.644Z</updated>
    
    <content type="html"><![CDATA[<p>主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。</p><p>哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis例。</p><p>这里的哨兵有两个作用</p><ul><li><p>通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。</p></li><li><p>当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。</p></li></ul><p>然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。</p><p>用文字描述一下故障切换（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。</p><p><img src="/img/Databases/redis/1.png" alt="image"></p><p>哨兵模式，搭建略</p><p>下面只介绍两条指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./redis-cli -h 172.17.36.53  -p 26379 info sentinel</span><br><span class="line"></span><br><span class="line"># Sentinel</span><br><span class="line">sentinel_masters:10</span><br><span class="line">sentinel_tilt:0</span><br><span class="line">sentinel_running_scripts:0</span><br><span class="line">sentinel_scripts_queue_length:0</span><br><span class="line">sentinel_simulate_failure_flags:0</span><br><span class="line">master0:name=mymaster,status=ok,address=172.17.53.12:6379,slaves=1,sentinels=3</span><br></pre></td></tr></table></figure><p>可查看到：</p><p>sentinel.master 为mymaster，以及redis-master得ip及端口，redis-slaves只有一个节点，一主一从，sentinel为三节点，高可用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">172.17.36.64:6379&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip=172.17.36.65,port=6379,state=online,offset=460794372,lag=0</span><br><span class="line">master_replid:2a496f16e40b6f4d48c89fa77495244b983b0a1e</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:460794372</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:32000000</span><br><span class="line">repl_backlog_first_byte_offset:428794373</span><br><span class="line">repl_backlog_histlen:32000000</span><br></pre></td></tr></table></figure><p>通过连接到master节点查看，可看到slaves所有节点的ip，端口</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。&lt;/p&gt;
&lt;p&gt;哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个
      
    
    </summary>
    
      <category term="Redis" scheme="http://macintosh-c.coding.me/categories/Redis/"/>
    
    
      <category term="Redis-Sentinel" scheme="http://macintosh-c.coding.me/tags/Redis-Sentinel/"/>
    
  </entry>
  
  <entry>
    <title>Springboot调优之内嵌Tomcat</title>
    <link href="http://macintosh-c.coding.me/2021/05/27/spring/Springboot/springboot%E8%B0%83%E4%BC%98%E4%B9%8B%E5%86%85%E5%B5%8Ctomcat/"/>
    <id>http://macintosh-c.coding.me/2021/05/27/spring/Springboot/springboot调优之内嵌tomcat/</id>
    <published>2021-05-26T17:29:05.000Z</published>
    <updated>2021-05-27T09:02:00.823Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Springboot调优之内嵌Tomcat"><a href="#Springboot调优之内嵌Tomcat" class="headerlink" title="Springboot调优之内嵌Tomcat"></a>Springboot调优之内嵌Tomcat</h2><p>怎么配置tomcat，才能使得自己的服务效率更高呢？</p><p>首先，这和tomcat的使用的IO模式有关，其次，也和tomcat的配置参数有关，尤其是以下三个配置项：maxConnections、maxThreads、acceptCount。</p><h4 id="Tomcat的高效配置"><a href="#Tomcat的高效配置" class="headerlink" title="Tomcat的高效配置"></a>Tomcat的高效配置</h4><p>Tomcat的maxConnections、maxThreads、acceptCount三大配置，分别表示最大连接数，最大线程数、最大的等待数，可以通过application.yml配置文件来改变这个三个值，一个标准的示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  tomcat:</span><br><span class="line">    uri-encoding: UTF-8</span><br><span class="line">    #最大工作线程数，默认200, 4核8g内存，线程数经验值800</span><br><span class="line">    #操作系统做线程之间的切换调度是有系统开销的，所以不是越多越好。</span><br><span class="line">    max-threads: 1000</span><br><span class="line">    # 等待队列长度，默认100</span><br><span class="line">   accept-count: 1000</span><br><span class="line">    max-connections: 20000</span><br><span class="line">    # 最小工作空闲线程数，默认10, 适当增大一些，以便应对突然增长的访问量</span><br><span class="line">   min-spare-threads: 100</span><br></pre></td></tr></table></figure><h4 id="详解：maxConnections、maxThreads、acceptCount"><a href="#详解：maxConnections、maxThreads、acceptCount" class="headerlink" title="详解：maxConnections、maxThreads、acceptCount"></a>详解：maxConnections、maxThreads、acceptCount</h4><p>一、accept-count：最大等待数</p><p>官方文档的说明为：当所有的请求处理线程都在使用时，所能接收的连接请求的队列的最大长度。当队列已满时，任何的连接请求都将被拒绝。accept-count的默认值为100。<br>详细的来说：当调用HTTP请求数达到tomcat的最大线程数时，还有新的HTTP请求到来，这时tomcat会将该请求放在等待队列中，这个acceptCount就是指能够接受的最大等待数，默认100。如果等待队列也被放满了，这个时候再来新的请求就会被tomcat拒绝（connection refused）。</p><p>二、maxThreads：最大线程数</p><p>每一次HTTP请求到达Web服务，tomcat都会创建一个线程来处理该请求，那么最大线程数决定了Web服务容器可以同时处理多少个请求。maxThreads默认200，肯定建议增加。但是，增加线程是有成本的，更多的线程，不仅仅会带来更多的线程上下文切换成本，而且意味着带来更多的内存消耗。JVM中默认情况下在创建新线程时会分配大小为1M的线程栈，所以，更多的线程异味着需要更多的内存。线程数的经验值为：1核2g内存为200，线程数经验值200；4核8g内存，线程数经验值800。</p><p>三、maxConnections：最大连接数</p><p>官方文档的说明为：</p><p>这个参数是指在同一时间，tomcat能够接受的最大连接数。对于Java的阻塞式BIO，默认值是maxthreads的值；如果在BIO模式使用定制的Executor执行器，默认值将是执行器中maxthreads的值。对于Java 新的NIO模式，maxConnections 默认值是10000。<br>对于windows上APR/native IO模式，maxConnections默认值为8192，这是出于性能原因，如果配置的值不是1024的倍数，maxConnections 的实际值将减少到1024的最大倍数。<br>如果设置为-1，则禁用maxconnections功能，表示不限制tomcat容器的连接数。<br>maxConnections和accept-count的关系为：当连接数达到最大值maxConnections后，系统会继续接收连接，但不会超过acceptCount的值。</p><h4 id="图解：maxConnections、maxThreads、acceptCount关系"><a href="#图解：maxConnections、maxThreads、acceptCount关系" class="headerlink" title="图解：maxConnections、maxThreads、acceptCount关系"></a>图解：maxConnections、maxThreads、acceptCount关系</h4><p>用一个形象的比喻，通俗易懂的解释一下tomcat的最大线程数（maxThreads）、最大等待数（acceptCount）和最大连接数（maxConnections）三者之间的关系。</p><p>我们可以把tomcat比做一个火锅店，流程是取号、入座、叫服务员，可以做一下三个形象的类比：</p><p>（1）acceptCount 最大等待数</p><p>可以类比为火锅店的排号处能够容纳排号的最大数量；排号的数量不是无限制的，火锅店的排号到了一定数据量之后，服务往往会说：已经客满。</p><p>（2）maxConnections 最大连接数</p><p>可以类比为火锅店的大堂的餐桌数量，也就是可以就餐的桌数。如果所有的桌子都已经坐满，则表示餐厅已满，已经达到了服务的数量上线，不能再有顾客进入餐厅了。</p><p>（3）maxThreads：最大线程数</p><p>可以类比为厨师的个数。每一个厨师，在同一时刻，只能给一张餐桌炒菜，就像极了JVM中的一条线程。</p><p>整个就餐的流程，大致如下：</p><p>（1）取号：如果maxConnections连接数没有满，就不需要取号，因为还有空余的餐桌，直接被大堂服务员领上餐桌，点菜就餐即可。如果 maxConnections 连接数满了，但是取号人数没有达到 acceptCount，则取号成功。如果取号人数已达到acceptCount，则拿号失败，会得到Tomcat的Connection refused connect 的回复信息。</p><p>（2）上桌：如果有餐桌空出来了，表示maxConnections连接数没有满，排队的人，可以进入大堂上桌就餐。</p><p>（3）就餐：就餐需要厨师炒菜。厨师的数量，比顾客的数量，肯定会少一些。一个厨师一定需要给多张餐桌炒菜，如果就餐的人越多，厨师也会忙不过来。这时候就可以增加厨师，一增加到上限maxThreads的值，如果还是不够，只能是拖慢每一张餐桌的上菜速度，这种情况，就是大家常见的“上一道菜吃光了，下一道菜还没有上”尴尬场景。</p><p><strong>maxConnections、maxThreads、acceptCount关系图如下</strong></p><p><img src="/img/Springboot/1.png" alt="image"></p><p>参考：<a href="https://www.cnblogs.com/crazymakercircle/p/11748214.html" target="_blank" rel="noopener">https://www.cnblogs.com/crazymakercircle/p/11748214.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Springboot调优之内嵌Tomcat&quot;&gt;&lt;a href=&quot;#Springboot调优之内嵌Tomcat&quot; class=&quot;headerlink&quot; title=&quot;Springboot调优之内嵌Tomcat&quot;&gt;&lt;/a&gt;Springboot调优之内嵌Tomcat&lt;/
      
    
    </summary>
    
      <category term="Springboot" scheme="http://macintosh-c.coding.me/categories/Springboot/"/>
    
    
      <category term="Springboot调优" scheme="http://macintosh-c.coding.me/tags/Springboot%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据迁移</title>
    <link href="http://macintosh-c.coding.me/2021/05/14/Databases/Redis/Redis%E5%8D%95%E5%AE%9E%E4%BE%8B%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BBCluster%E6%96%B9%E6%A1%88blog/"/>
    <id>http://macintosh-c.coding.me/2021/05/14/Databases/Redis/Redis单实例数据迁移Cluster方案blog/</id>
    <published>2021-05-14T04:20:29.000Z</published>
    <updated>2021-05-14T05:26:54.714Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis单实例数据迁移Cluster方案"><a href="#Redis单实例数据迁移Cluster方案" class="headerlink" title="Redis单实例数据迁移Cluster方案"></a>Redis单实例数据迁移Cluster方案</h2><p>[TOC]</p><blockquote><p>方案1:RDB文件数据恢复</p></blockquote><blockquote><p>方案2:import 直接导入（ 建议）</p></blockquote><h3 id="目标集群介绍"><a href="#目标集群介绍" class="headerlink" title="目标集群介绍"></a>目标集群介绍</h3><p>以生产环境12主12从为例,集群搭建 略<br>集群信息如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">9e051ce8d91148d5079164bb8cc436f0da478cec 172.16.33.251:7000@17000 master - 0 1620720637417 1 connected 0-1364</span><br><span class="line">ab1e21eb94f59cbf5e963da838950b369bc800dd 172.16.33.251:7001@17001 master - 0 1620720635000 2 connected 8192-9556</span><br><span class="line">3fb819143290fc2108f69268db86729fb6f139cd 172.16.33.251:7002@17002 slave f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 0 1620720635915 13 connected</span><br><span class="line">082932fb5be5f163ce375d325acd6005060dfab1 172.16.33.251:7003@17003 slave 19fffc48fad2d724a3d8f3a70ef05bcdc453bc31 0 1620720636415 14 connected</span><br><span class="line"></span><br><span class="line">f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 172.16.33.252:7000@17000 master - 0 1620720634000 3 connected 1365-2730</span><br><span class="line">19fffc48fad2d724a3d8f3a70ef05bcdc453bc31 172.16.33.252:7001@17001 master - 0 1620720634512 4 connected 9557-10922</span><br><span class="line">a5c35d09512fa360eadfbee5a97cbc4fd02f1b82 172.16.33.252:7002@17002 slave 9e051ce8d91148d5079164bb8cc436f0da478cec 0 1620720635000 15 connected</span><br><span class="line">4629b7f6a54df283995eb1dfda1bec28c3938351 172.16.33.252:7003@17003 slave ab1e21eb94f59cbf5e963da838950b369bc800dd 0 1620720634000 16 connected</span><br><span class="line"></span><br><span class="line">efce1b72390ee8cd862a0b442263c40e90910f60 172.16.33.253:7000@17000 master - 0 1620720637518 5 connected 2731-4095</span><br><span class="line">d7f46f5bdc5f22a16253994bceadfbf155e8b3a5 172.16.33.253:7001@17001 master - 0 1620720635000 6 connected 10923-12287</span><br><span class="line">6f0a52a2231e85978fc5bd7a74561ad52d4b0faf 172.16.33.253:7002@17002 slave f487b73102c6b5776c95588870261d6ac8c5ae83 0 1620720635414 17 connected</span><br><span class="line">05542924f7a73edca3094d882826a778bfaaa6ab 172.16.33.253:7003@17003 slave cd787484b0dfa4ac2c3832e86cd1fd37306366ed 0 1620720636000 18 connected</span><br><span class="line"></span><br><span class="line">f487b73102c6b5776c95588870261d6ac8c5ae83 172.16.34.1:7000@17000 master - 0 1620720635513 7 connected 4096-5460</span><br><span class="line">cd787484b0dfa4ac2c3832e86cd1fd37306366ed 172.16.34.1:7001@17001 master - 0 1620720635000 8 connected 12288-13652</span><br><span class="line">56a2a8e24057b5286b8601ce517af0f9499f94b6 172.16.34.1:7002@17002 slave efce1b72390ee8cd862a0b442263c40e90910f60 0 1620720637000 19 connected</span><br><span class="line">438967554aa082339108743a913be0b4ac36fda8 172.16.34.1:7003@17003 slave d7f46f5bdc5f22a16253994bceadfbf155e8b3a5 0 1620720638000 20 connected</span><br><span class="line"></span><br><span class="line">426ccc5185f423cf0ce8456ab0c168948103d2b8 172.16.34.2:7000@17000 master - 0 1620720638520 9 connected 5461-6826</span><br><span class="line">29e5b98fbe4a56516779c66f49843aae694d868b 172.16.34.2:7001@17001 master - 0 1620720639422 10 connected 13653-15018</span><br><span class="line">15b06a247c5851f34288cc95a08afbaa636cdf15 172.16.34.2:7002@17002 slave 44c63289731aacec61959961d9061e70885e670a 0 1620720636000 21 connected</span><br><span class="line">9da3e9f887a59fa5357614373a26a4df24dd0e4b 172.16.34.2:7003@17003 slave 00f5deaaf6bca42156ee10f815741285a84c86ef 0 1620720636000 22 connected</span><br><span class="line"></span><br><span class="line">44c63289731aacec61959961d9061e70885e670a 172.16.34.3:7000@17000 myself,master - 0 1620720631000 11 connected 6827-8191</span><br><span class="line">00f5deaaf6bca42156ee10f815741285a84c86ef 172.16.34.3:7001@17001 master - 0 1620720635000 12 connected 15019-16383</span><br><span class="line">959db0b50a82e02697b42f337603cfa9e8f7ef5d 172.16.34.3:7002@17002 slave 426ccc5185f423cf0ce8456ab0c168948103d2b8 0 1620720638420 23 connected</span><br><span class="line">2a4c1c17c460eb9b15dfde6ea1e5507f11dade12 172.16.34.3:7003@17003 slave 29e5b98fbe4a56516779c66f49843aae694d868b 0 1620720637518 24 connected</span><br></pre></td></tr></table></figure><p>各配置文件路径如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">config路径:/etc/redis/</span><br><span class="line">redis按照包:/data/redis-5.0.2/</span><br><span class="line">redis-cli指令路径：/usr/local/bin/</span><br><span class="line">持久化路径：/data/redis-cluster/</span><br></pre></td></tr></table></figure></p><p>查看各redis服务情况：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">服务状态查看：systemctl status redis_7000.service</span><br></pre></td></tr></table></figure></p><h3 id="RDB文件数据恢复"><a href="#RDB文件数据恢复" class="headerlink" title="RDB文件数据恢复"></a>RDB文件数据恢复</h3><blockquote><p>原数据源只能导出RDB文件，且为单文件</p></blockquote><blockquote><p>新集群配置持久化为AOF</p></blockquote><p>迁移步骤如下：</p><h4 id="1-去除所有slave节点"><a href="#1-去除所有slave节点" class="headerlink" title="1. 去除所有slave节点"></a>1. 去除所有slave节点</h4><p>例：( 执行所有)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster del-node 172.16.34.3:7003 2a4c1c17c460eb9b15dfde6ea1e5507f11dade12 -a ****</span><br></pre></td></tr></table></figure></p><p>去除slave后cluster  nodes 状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">9e051ce8d91148d5079164bb8cc436f0da478cec 172.16.33.251:7000@17000 myself,master - 0 1620886282000 25 connected 15019-16383</span><br><span class="line">efce1b72390ee8cd862a0b442263c40e90910f60 172.16.33.253:7000@17000 master - 0 1620886281000 29 connected 4097-5462</span><br><span class="line">29e5b98fbe4a56516779c66f49843aae694d868b 172.16.34.2:7001@17001 master - 0 1620886284000 33 connected 9560-10924</span><br><span class="line">cd787484b0dfa4ac2c3832e86cd1fd37306366ed 172.16.34.1:7001@17001 master - 0 1620886283000 36 connected 1365 13655-15018</span><br><span class="line">44c63289731aacec61959961d9061e70885e670a 172.16.34.3:7000@17000 master - 0 1620886281528 28 connected 2731-4096</span><br><span class="line">19fffc48fad2d724a3d8f3a70ef05bcdc453bc31 172.16.33.252:7001@17001 master - 0 1620886285535 32 connected 8195-9559</span><br><span class="line">f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 172.16.33.252:7000@17000 master - 0 1620886282000 27 connected 1366-2730</span><br><span class="line">426ccc5185f423cf0ce8456ab0c168948103d2b8 172.16.34.2:7000@17000 master - 0 1620886280000 31 connected 6829-8194</span><br><span class="line">ab1e21eb94f59cbf5e963da838950b369bc800dd 172.16.33.251:7001@17001 master - 0 1620886282000 26 connected 0-1364</span><br><span class="line">f487b73102c6b5776c95588870261d6ac8c5ae83 172.16.34.1:7000@17000 master - 0 1620886284032 34 connected 10925-12289</span><br><span class="line">d7f46f5bdc5f22a16253994bceadfbf155e8b3a5 172.16.33.253:7001@17001 master - 0 1620886283531 30 connected 5463-6828</span><br><span class="line">00f5deaaf6bca42156ee10f815741285a84c86ef 172.16.34.3:7001@17001 master - 0 1620886284533 35 connected 12290-13654</span><br></pre></td></tr></table></figure></p><h4 id="2-停掉所有slave服务"><a href="#2-停掉所有slave服务" class="headerlink" title="2. 停掉所有slave服务"></a>2. 停掉所有slave服务</h4><p>例：( 执行所有)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop redis_7003</span><br></pre></td></tr></table></figure><h4 id="3-将所有master的slot-迁移到-其中1个-主-master"><a href="#3-将所有master的slot-迁移到-其中1个-主-master" class="headerlink" title="3. 将所有master的slot 迁移到 其中1个 主 master"></a>3. 将所有master的slot 迁移到 其中1个 主 master</h4><p>迁移前：</p><p><code>redis-cli --cluster check 172.16.33.251:7000 -a ****</code>检测集群</p><p>可查看到各节点预分槽分数量和分布<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">172.16.33.251:7000 (9e051ce8...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.33.253:7000 (efce1b72...) -&gt; 0 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.34.2:7001 (29e5b98f...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.1:7001 (cd787484...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.3:7000 (44c63289...) -&gt; 0 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.33.252:7001 (19fffc48...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.33.252:7000 (f2ac6cad...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.2:7000 (426ccc51...) -&gt; 0 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.33.251:7001 (ab1e21eb...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.1:7000 (f487b731...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.33.253:7001 (d7f46f5b...) -&gt; 0 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.34.3:7001 (00f5deaa...) -&gt; 0 keys | 1365 slots | 0 slaves.</span><br><span class="line">[OK] 0 keys in 12 masters.</span><br><span class="line">0.00 keys per slot on average.</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 172.16.33.251:7000)</span><br><span class="line">M: 9e051ce8d91148d5079164bb8cc436f0da478cec 172.16.33.251:7000</span><br><span class="line">   slots:[15019-16383] (1365 slots) master</span><br><span class="line">M: efce1b72390ee8cd862a0b442263c40e90910f60 172.16.33.253:7000</span><br><span class="line">   slots:[4097-5462] (1366 slots) master</span><br><span class="line">M: 29e5b98fbe4a56516779c66f49843aae694d868b 172.16.34.2:7001</span><br><span class="line">   slots:[9560-10924] (1365 slots) master</span><br><span class="line">M: cd787484b0dfa4ac2c3832e86cd1fd37306366ed 172.16.34.1:7001</span><br><span class="line">   slots:[1365],[13655-15018] (1365 slots) master</span><br><span class="line">M: 44c63289731aacec61959961d9061e70885e670a 172.16.34.3:7000</span><br><span class="line">   slots:[2731-4096] (1366 slots) master</span><br><span class="line">M: 19fffc48fad2d724a3d8f3a70ef05bcdc453bc31 172.16.33.252:7001</span><br><span class="line">   slots:[8195-9559] (1365 slots) master</span><br><span class="line">M: f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 172.16.33.252:7000</span><br><span class="line">   slots:[1366-2730] (1365 slots) master</span><br><span class="line">M: 426ccc5185f423cf0ce8456ab0c168948103d2b8 172.16.34.2:7000</span><br><span class="line">   slots:[6829-8194] (1366 slots) master</span><br><span class="line">M: ab1e21eb94f59cbf5e963da838950b369bc800dd 172.16.33.251:7001</span><br><span class="line">   slots:[0-1364] (1365 slots) master</span><br><span class="line">M: f487b73102c6b5776c95588870261d6ac8c5ae83 172.16.34.1:7000</span><br><span class="line">   slots:[10925-12289] (1365 slots) master</span><br><span class="line">M: d7f46f5bdc5f22a16253994bceadfbf155e8b3a5 172.16.33.253:7001</span><br><span class="line">   slots:[5463-6828] (1366 slots) master</span><br><span class="line">M: 00f5deaaf6bca42156ee10f815741285a84c86ef 172.16.34.3:7001</span><br><span class="line">   slots:[12290-13654] (1365 slots) master</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure></p><p>迁移指令：</p><p>例：( 执行所有)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster reshard 172.16.33.251:7000 --cluster-from ab1e21eb94f59cbf5e963da838950b369bc800dd --cluster-to 9e051ce8d91148d5079164bb8cc436f0da478cec --cluster-slots 1365 --cluster-yes --cluster-timeout 5000 --cluster-pipeline 10 --cluster-replace -a *****</span><br></pre></td></tr></table></figure><p>迁移slot后检测：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">172.16.33.251:7000 (9e051ce8...) -&gt; 0 keys | 16384 slots | 0 slaves.</span><br><span class="line">172.16.33.253:7000 (efce1b72...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.34.2:7001 (29e5b98f...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.34.1:7001 (cd787484...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.34.3:7000 (44c63289...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.33.252:7001 (19fffc48...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.33.252:7000 (f2ac6cad...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.34.2:7000 (426ccc51...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.33.251:7001 (ab1e21eb...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.34.1:7000 (f487b731...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.33.253:7001 (d7f46f5b...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">172.16.34.3:7001 (00f5deaa...) -&gt; 0 keys | 0 slots | 0 slaves.</span><br><span class="line">[OK] 0 keys in 12 masters.</span><br><span class="line">0.00 keys per slot on average.</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 172.16.33.251:7000)</span><br><span class="line">M: 9e051ce8d91148d5079164bb8cc436f0da478cec 172.16.33.251:7000</span><br><span class="line">   slots:[0-16383] (16384 slots) master</span><br><span class="line">M: efce1b72390ee8cd862a0b442263c40e90910f60 172.16.33.253:7000</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: 29e5b98fbe4a56516779c66f49843aae694d868b 172.16.34.2:7001</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: cd787484b0dfa4ac2c3832e86cd1fd37306366ed 172.16.34.1:7001</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: 44c63289731aacec61959961d9061e70885e670a 172.16.34.3:7000</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: 19fffc48fad2d724a3d8f3a70ef05bcdc453bc31 172.16.33.252:7001</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 172.16.33.252:7000</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: 426ccc5185f423cf0ce8456ab0c168948103d2b8 172.16.34.2:7000</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: ab1e21eb94f59cbf5e963da838950b369bc800dd 172.16.33.251:7001</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: f487b73102c6b5776c95588870261d6ac8c5ae83 172.16.34.1:7000</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: d7f46f5bdc5f22a16253994bceadfbf155e8b3a5 172.16.33.253:7001</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">M: 00f5deaaf6bca42156ee10f815741285a84c86ef 172.16.34.3:7001</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure></p><p>16384个slot全部移动到了172.16.33.251:7000节点</p><h4 id="4-此-主master-关闭aof功能，让其以rdb文件恢复数据"><a href="#4-此-主master-关闭aof功能，让其以rdb文件恢复数据" class="headerlink" title="4. 此 主master 关闭aof功能，让其以rdb文件恢复数据"></a>4. 此 主master 关闭aof功能，让其以rdb文件恢复数据</h4><p>编辑config文件<br>设置<br>appendonly no    </p><h4 id="5-copy-原rdb-文件到目标-节点的-rdb文件位置"><a href="#5-copy-原rdb-文件到目标-节点的-rdb文件位置" class="headerlink" title="5. copy 原rdb 文件到目标 节点的 rdb文件位置"></a>5. copy 原rdb 文件到目标 节点的 rdb文件位置</h4><p><code>cp ../s00208nprediswehcat3-0 dump_7000.rdb</code></p><h4 id="6-重启此-master-redis"><a href="#6-重启此-master-redis" class="headerlink" title="6. 重启此 master redis"></a>6. 重启此 master redis</h4><p><code>sudo systemctl restart redis_7000</code></p><h4 id="7-登录此redis，校验数据完整性"><a href="#7-登录此redis，校验数据完整性" class="headerlink" title="7. 登录此redis，校验数据完整性"></a>7. 登录此redis，校验数据完整性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7000 -a ****</span><br><span class="line"></span><br><span class="line">127.0.0.1:7000&gt; dbsize</span><br><span class="line">(integer) 684</span><br></pre></td></tr></table></figure><h4 id="8-重平衡所有的slot到各master节点"><a href="#8-重平衡所有的slot到各master节点" class="headerlink" title="8. 重平衡所有的slot到各master节点"></a>8. 重平衡所有的slot到各master节点</h4><p><code>redis-cli --cluster rebalance 172.16.33.251:7000 --cluster-use-empty-masters -a ******</code></p><p>重平衡后:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">172.16.33.251:7000 (9e051ce8...) -&gt; 55 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.3:7000 (44c63289...) -&gt; 56 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.34.2:7001 (29e5b98f...) -&gt; 56 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.33.251:7001 (ab1e21eb...) -&gt; 50 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.34.3:7001 (00f5deaa...) -&gt; 61 keys | 1366 slots | 0 slaves.</span><br><span class="line">172.16.33.252:7001 (19fffc48...) -&gt; 58 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.1:7001 (cd787484...) -&gt; 55 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.33.252:7000 (f2ac6cad...) -&gt; 50 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.2:7000 (426ccc51...) -&gt; 63 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.33.253:7001 (d7f46f5b...) -&gt; 57 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.33.253:7000 (efce1b72...) -&gt; 64 keys | 1365 slots | 0 slaves.</span><br><span class="line">172.16.34.1:7000 (f487b731...) -&gt; 59 keys | 1365 slots | 0 slaves.</span><br><span class="line">[OK] 684 keys in 12 masters.</span><br><span class="line">0.04 keys per slot on average.</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 172.16.33.251:7000)</span><br><span class="line">M: 9e051ce8d91148d5079164bb8cc436f0da478cec 172.16.33.251:7000</span><br><span class="line">   slots:[15019-16383] (1365 slots) master</span><br><span class="line">M: 44c63289731aacec61959961d9061e70885e670a 172.16.34.3:7000</span><br><span class="line">   slots:[0-1365] (1366 slots) master</span><br><span class="line">M: 29e5b98fbe4a56516779c66f49843aae694d868b 172.16.34.2:7001</span><br><span class="line">   slots:[1366-2731] (1366 slots) master</span><br><span class="line">M: ab1e21eb94f59cbf5e963da838950b369bc800dd 172.16.33.251:7001</span><br><span class="line">   slots:[2732-4097] (1366 slots) master</span><br><span class="line">M: 00f5deaaf6bca42156ee10f815741285a84c86ef 172.16.34.3:7001</span><br><span class="line">   slots:[4098-5463] (1366 slots) master</span><br><span class="line">M: 19fffc48fad2d724a3d8f3a70ef05bcdc453bc31 172.16.33.252:7001</span><br><span class="line">   slots:[5464-6828] (1365 slots) master</span><br><span class="line">M: cd787484b0dfa4ac2c3832e86cd1fd37306366ed 172.16.34.1:7001</span><br><span class="line">   slots:[6829-8193] (1365 slots) master</span><br><span class="line">M: f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 172.16.33.252:7000</span><br><span class="line">   slots:[8194-9558] (1365 slots) master</span><br><span class="line">M: 426ccc5185f423cf0ce8456ab0c168948103d2b8 172.16.34.2:7000</span><br><span class="line">   slots:[9559-10923] (1365 slots) master</span><br><span class="line">M: d7f46f5bdc5f22a16253994bceadfbf155e8b3a5 172.16.33.253:7001</span><br><span class="line">   slots:[10924-12288] (1365 slots) master</span><br><span class="line">M: efce1b72390ee8cd862a0b442263c40e90910f60 172.16.33.253:7000</span><br><span class="line">   slots:[12289-13653] (1365 slots) master</span><br><span class="line">M: f487b73102c6b5776c95588870261d6ac8c5ae83 172.16.34.1:7000</span><br><span class="line">   slots:[13654-15018] (1365 slots) master</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure></p><h4 id="9-指令开启主-master的-aof功能，生成此master-的aof文件，其他节点默认开启，可看到aof文件已默认生成"><a href="#9-指令开启主-master的-aof功能，生成此master-的aof文件，其他节点默认开启，可看到aof文件已默认生成" class="headerlink" title="9. 指令开启主 master的 aof功能，生成此master 的aof文件，其他节点默认开启，可看到aof文件已默认生成"></a>9. 指令开启主 master的 aof功能，生成此master 的aof文件，其他节点默认开启，可看到aof文件已默认生成</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -c -p 7000 -a *****</span><br><span class="line">config get appendonly</span><br><span class="line">config set appendonly yes</span><br><span class="line">config get appendonly</span><br></pre></td></tr></table></figure><p><strong>注意，不做这一步，后面重启该节点的redis，则该节点数据会丢失！！！</strong></p><h4 id="10-打开主master配置的aof功能，重启主-master"><a href="#10-打开主master配置的aof功能，重启主-master" class="headerlink" title="10. 打开主master配置的aof功能，重启主 master"></a>10. 打开主master配置的aof功能，重启主 master</h4><p>编辑config文件<br>设置<br>appendonly yes    </p><p>重启：<br><code>sudo systemctl restart redis_7000</code></p><h4 id="11-启动添加slave节点"><a href="#11-启动添加slave节点" class="headerlink" title="11. 启动添加slave节点"></a>11. 启动添加slave节点</h4><p>删除所有slave节点的数据文件：appendonly_7002.aof,dump_7002.rdb,node_7002.conf</p><p>启动所有slave节点，例：sudo systemctl start redis_7002</p><p>根据原来的主从关系添加从节点到指定的原master节点下：</p><p>例：( 执行所有)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster add-node 172.16.33.251:7002 172.16.33.251:7000 --cluster-slave --cluster-master-id f2ac6cada2bd5a3cc2aee46da3d85a7127b38313 -a *****</span><br></pre></td></tr></table></figure></p><h4 id="12-集群确认，以及主从切换正常"><a href="#12-集群确认，以及主从切换正常" class="headerlink" title="12. 集群确认，以及主从切换正常"></a>12. 集群确认，以及主从切换正常</h4><p>登录新集群cluster nodes查看, 集群关系正常，手动停掉其中一个master，再次查看，会看到对应的从已切换为主，且整个集群读写正常，再此启动该master，此master自动为从，数据正常无丢失，集群即为正常。</p><h3 id="import-直接导入"><a href="#import-直接导入" class="headerlink" title="import 直接导入"></a>import 直接导入</h3><blockquote><p>此方法可直接从原redis 导入数据到 目标 cluster集群，不需要中间的rdb文件拷贝恢复，由于我们的数据源是在azure，并不能直接打通环境，而且只能导出rdb文件，所有本地再起一个单机的备用redis，此单机和目标cluster没有任何关联，只用来容纳从azure迁移下来的数据，从单机到单机很方便，不需要移动slot槽即可迁移完毕，作为原数据源。</p></blockquote><h4 id="1-创建一个单机redis服务7004端口"><a href="#1-创建一个单机redis服务7004端口" class="headerlink" title="1. 创建一个单机redis服务7004端口"></a>1. 创建一个单机redis服务7004端口</h4><p>拷贝各配置文件，改配置为172.16.33.251 的7004端口启动，且关闭AOF，使其可以通过rdb恢复数据，不需要设置密码</p><h4 id="2-copy-源rdb文件-替换-到7004-redis服务rdb文件dump-7004-rdb"><a href="#2-copy-源rdb文件-替换-到7004-redis服务rdb文件dump-7004-rdb" class="headerlink" title="2. copy 源rdb文件 替换 到7004 redis服务rdb文件dump_7004.rdb"></a>2. copy 源rdb文件 替换 到7004 redis服务rdb文件dump_7004.rdb</h4><h4 id="3-启动7004端口redis服务，检测数据"><a href="#3-启动7004端口redis服务，检测数据" class="headerlink" title="3. 启动7004端口redis服务，检测数据"></a>3. 启动7004端口redis服务，检测数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7004 </span><br><span class="line"></span><br><span class="line">127.0.0.1:7000&gt; dbsize</span><br><span class="line">(integer) 684</span><br></pre></td></tr></table></figure><h4 id="4-设置目标cluster集群的密码为空"><a href="#4-设置目标cluster集群的密码为空" class="headerlink" title="4. 设置目标cluster集群的密码为空"></a>4. 设置目标cluster集群的密码为空</h4><p>修改对应的conf文件，注释掉密码，重启各节点服务，验证已无auth认证</p><h4 id="5-导入集群"><a href="#5-导入集群" class="headerlink" title="5. 导入集群"></a>5. 导入集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster import 172.16.33.251:7000 --cluster-from 172.16.33.251:7004 --cluster-replace</span><br></pre></td></tr></table></figure><p><strong>注意：测试下来发现参数–cluster-replace没有用，如果集群中已经包含了某个key，在导入的时候会失败，不会覆盖，只有清空集群key才能导入。</strong></p><h4 id="6-确认导入后数据完整性"><a href="#6-确认导入后数据完整性" class="headerlink" title="6. 确认导入后数据完整性"></a>6. 确认导入后数据完整性</h4><p>依次跳转到各redis节点服务，查看数据量，最后计算数据总量与原7004中数据总量一致。<br>此方法不需要复杂的slot迁移与重平衡，相对比较容易。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis单实例数据迁移Cluster方案&quot;&gt;&lt;a href=&quot;#Redis单实例数据迁移Cluster方案&quot; class=&quot;headerlink&quot; title=&quot;Redis单实例数据迁移Cluster方案&quot;&gt;&lt;/a&gt;Redis单实例数据迁移Cluster方案&lt;/
      
    
    </summary>
    
      <category term="Redis" scheme="http://macintosh-c.coding.me/categories/Redis/"/>
    
    
      <category term="Redis数据迁移" scheme="http://macintosh-c.coding.me/tags/Redis%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/"/>
    
  </entry>
  
  <entry>
    <title>Redis Cluster集群操作说明</title>
    <link href="http://macintosh-c.coding.me/2021/05/13/Databases/Redis/Redis5.0%20redis-cli%20--cluster%20help%E8%AF%B4%E6%98%8E/"/>
    <id>http://macintosh-c.coding.me/2021/05/13/Databases/Redis/Redis5.0 redis-cli --cluster help说明/</id>
    <published>2021-05-13T04:20:29.000Z</published>
    <updated>2021-05-14T05:46:09.569Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis-5-0-redis-cli-–cluster-help说明"><a href="#Redis-5-0-redis-cli-–cluster-help说明" class="headerlink" title="Redis 5.0 redis-cli –cluster help说明"></a>Redis 5.0 redis-cli –cluster help说明</h2><blockquote><p>背景：Redis Cluster 在5.0之后取消了ruby脚本 redis-trib.rb的支持（手动命令行添加集群的方式不变），集合到redis-cli里，避免了再安装ruby的相关环境。直接使用redis-clit的参数–cluster 来取代。为方便自己后面查询就说明下如何使用该命令进行Cluster的创建和管理，关于Cluster的相关说明可以查看官网或则Redis Cluster部署、管理和测试。</p></blockquote><p>说明：redis-cli –cluster help</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster help</span><br><span class="line">Cluster Manager Commands:</span><br><span class="line">  create         host1:port1 ... hostN:portN   #创建集群</span><br><span class="line">                 --cluster-replicas &lt;arg&gt;      #从节点个数</span><br><span class="line">  check          host:port                     #检查集群</span><br><span class="line">                 --cluster-search-multiple-owners #检查是否有槽同时被分配给了多个节点</span><br><span class="line">  info           host:port                     #查看集群状态</span><br><span class="line">  fix            host:port                     #修复集群</span><br><span class="line">                 --cluster-search-multiple-owners #修复槽的重复分配问题</span><br><span class="line">  reshard        host:port                     #指定集群的任意一节点进行迁移slot，重新分slots</span><br><span class="line">                 --cluster-from &lt;arg&gt;          #需要从哪些源节点上迁移slot，可从多个源节点完成迁移，以逗号隔开，传递的是节点的node id，还可以直接传递--from all，这样源节点就是集群的所有节点，不传递该参数的话，则会在迁移过程中提示用户输入</span><br><span class="line">                 --cluster-to &lt;arg&gt;            #slot需要迁移的目的节点的node id，目的节点只能填写一个，不传递该参数的话，则会在迁移过程中提示用户输入</span><br><span class="line">                 --cluster-slots &lt;arg&gt;         #需要迁移的slot数量，不传递该参数的话，则会在迁移过程中提示用户输入。</span><br><span class="line">                 --cluster-yes                 #指定迁移时的确认输入</span><br><span class="line">                 --cluster-timeout &lt;arg&gt;       #设置migrate命令的超时时间</span><br><span class="line">                 --cluster-pipeline &lt;arg&gt;      #定义cluster getkeysinslot命令一次取出的key数量，不传的话使用默认值为10</span><br><span class="line">                 --cluster-replace             #是否直接replace到目标节点</span><br><span class="line">  rebalance      host:port                                      #指定集群的任意一节点进行平衡集群节点slot数量 </span><br><span class="line">                 --cluster-weight &lt;node1=w1...nodeN=wN&gt;         #指定集群节点的权重</span><br><span class="line">                 --cluster-use-empty-masters                    #设置可以让没有分配slot的主节点参与，默认不允许</span><br><span class="line">                 --cluster-timeout &lt;arg&gt;                        #设置migrate命令的超时时间</span><br><span class="line">                 --cluster-simulate                             #模拟rebalance操作，不会真正执行迁移操作</span><br><span class="line">                 --cluster-pipeline &lt;arg&gt;                       #定义cluster getkeysinslot命令一次取出的key数量，默认值为10</span><br><span class="line">                 --cluster-threshold &lt;arg&gt;                      #迁移的slot阈值超过threshold，执行rebalance操作</span><br><span class="line">                 --cluster-replace                              #是否直接replace到目标节点</span><br><span class="line">  add-node       new_host:new_port existing_host:existing_port  #添加节点，把新节点加入到指定的集群，默认添加主节点</span><br><span class="line">                 --cluster-slave                                #新节点作为从节点，默认随机一个主节点</span><br><span class="line">                 --cluster-master-id &lt;arg&gt;                      #给新节点指定主节点</span><br><span class="line">  del-node       host:port node_id                              #删除给定的一个节点，成功后关闭该节点服务</span><br><span class="line">  call           host:port command arg arg .. arg               #在集群的所有节点执行相关命令</span><br><span class="line">  set-timeout    host:port milliseconds                         #设置cluster-node-timeout</span><br><span class="line">  import         host:port                                      #将外部redis数据导入集群</span><br><span class="line">                 --cluster-from &lt;arg&gt;                           #将指定实例的数据导入到集群</span><br><span class="line">                 --cluster-copy                                 #migrate时指定copy</span><br><span class="line">                 --cluster-replace                              #migrate时指定replace</span><br><span class="line">  help           </span><br><span class="line"></span><br><span class="line">For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.</span><br></pre></td></tr></table></figure><p>注意：Redis Cluster最低要求是3个主节点，如果需要集群需要认证，则在最后加入 -a xx 即可。</p><ol><li>创建集群主节点</li></ol><p><code>redis-cli --cluster create 192.168.163.132:6379 192.168.163.132:6380 192.168.163.132:6381</code></p><ol start="2"><li>创建集群主从节点</li></ol><p><code>/redis-cli --cluster create 192.168.163.132:6379 192.168.163.132:6380 192.168.163.132:6381 192.168.163.132:6382 192.168.163.132:6383 192.168.163.132:6384 --cluster-replicas 1</code></p><p>说明：–cluster-replicas 参数为数字，1表示每个主节点需要1个从节点。</p><p>通过该方式创建的带有从节点的机器不能够自己手动指定主节点，所以如果需要指定的话，需要自己手动指定，先使用1或3创建好主节点后，再通过4来处理。</p><ol start="3"><li>添加集群主节点</li></ol><p><code>redis-cli --cluster add-node 192.168.163.132:6382 192.168.163.132:6379</code></p><p>说明：为一个指定集群添加节点，需要先连到该集群的任意一个节点IP（192.168.163.132:6379），再把新节点加入。该2个参数的顺序有要求：新加入的节点放前</p><ol start="4"><li>添加集群从节点</li></ol><p><code>redis-cli --cluster add-node 192.168.163.132:6382 192.168.163.132:6379 --cluster-slave --cluster-master-id 117457eab5071954faab5e81c3170600d5192270</code></p><p>说明：把6382节点加入到6379节点的集群中，并且当做node_id为 117457eab5071954faab5e81c3170600d5192270 的从节点。如果不指定 –cluster-master-id 会随机分配到任意一个主节点。</p><ol start="5"><li>删除节点</li></ol><p><code>redis-cli --cluster del-node 192.168.163.132:6384 f6a6957421b80409106cb36be3c7ba41f3b603ff</code></p><p>说明：指定IP、端口和node_id 来删除一个节点，从节点可以直接删除，有slot分配的主节点不能直接删除。</p><p>注意：当被删除掉的节点重新起来之后不能自动加入集群，但其和主的复制还是正常的，也可以通过该节点看到集群信息（通过其他正常节点已经看不到该被del-node节点的信息）。</p><p>如果想要再次加入集群，则需要先在该节点执行cluster reset，再用add-node进行添加，进行增量同步复制。</p><p>到此，目前整个集群的状态如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">192.168.163.132:6379&gt; cluster nodes</span><br><span class="line">815da8448f5d5a304df0353ca10d8f9b77016b28 192.168.163.132:6380@16380 master - 0 1569748297177 2 connected 5461-10922</span><br><span class="line">0c21b6cee354594a23f4d5abf0d01b48bdc96d55 192.168.163.132:6383@16383 slave 56005b9413cbf225783906307a2631109e753f8f 0 1569748295000 4 connected</span><br><span class="line">3a1d04983ab6c4ae853f9602dd922d4ebadc4dbf 192.168.163.132:6382@16382 slave 815da8448f5d5a304df0353ca10d8f9b77016b28 0 1569748295000 5 connected</span><br><span class="line">117457eab5071954faab5e81c3170600d5192270 192.168.163.132:6379@16379 myself,master - 0 1569748297000 1 connected 0-5460</span><br><span class="line">56005b9413cbf225783906307a2631109e753f8f 192.168.163.132:6381@16381 master - 0 1569748295000 3 connected 10923-16383</span><br><span class="line">f6a6957421b80409106cb36be3c7ba41f3b603ff 192.168.163.132:6384@16384 slave 117457eab5071954faab5e81c3170600d5192270 0 1569748298185 6 connected</span><br></pre></td></tr></table></figure></p><ol start="6"><li>检查集群</li></ol><p><code>redis-cli --cluster check 192.168.163.132:6384 --cluster-search-multiple-owners</code></p><p>说明：任意连接一个集群节点，进行集群状态检查</p><ol start="7"><li>集群信息查看</li></ol><p><code>redis-cli --cluster info 192.168.163.132:6384</code></p><p>说明：检查key、slots、从节点个数的分配情况</p><ol start="8"><li>修复集群</li></ol><p><code>redis-cli --cluster fix 192.168.163.132:6384 --cluster-search-multiple-owners</code></p><p>说明：修复集群和槽的重复分配问题</p><ol start="9"><li>设置集群的超时时间 </li></ol><p><code>redis-cli --cluster set-timeout 192.168.163.132:6382 10000</code></p><p>说明：连接到集群的任意一节点来设置集群的超时时间参数cluster-node-timeout</p><ol start="10"><li>集群中执行相关命令</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster call 192.168.163.132:6381 config set requirepass cc</span><br><span class="line">redis-cli -a cc --cluster call 192.168.163.132:6381 config set masterauth cc</span><br><span class="line">redis-cli -a cc --cluster call 192.168.163.132:6381 config rewrite</span><br></pre></td></tr></table></figure><p>说明：连接到集群的任意一节点来对整个集群的所有节点进行设置。</p><p>到此，相关集群的基本操作已经介绍完，现在说明集群迁移的相关操作。</p><h2 id="迁移相关"><a href="#迁移相关" class="headerlink" title="迁移相关"></a>迁移相关</h2><ol><li>在线迁移slot ：在线把集群的一些slot从集群原来slot节点迁移到新的节点，即可以完成集群的在线横向扩容和缩容。有2种方式进行迁移</li></ol><p>一是根据提示来进行操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">直接连接到集群的任意一节点</span><br><span class="line">redis-cli -a cc --cluster reshard 192.168.163.132:6379</span><br></pre></td></tr></table></figure><p>二是根据参数进行操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a cc --cluster reshard 192.168.163.132:6379 --cluster-from 117457eab5071954faab5e81c3170600d5192270 --cluster-to 815da8448f5d5a304df0353ca10d8f9b77016b28 --cluster-slots 10 --cluster-yes --cluster-timeout 5000 --cluster-pipeline 10 --cluster-replace</span><br></pre></td></tr></table></figure></p><p>说明：连接到集群的任意一节点来对指定节点指定数量的slot进行迁移到指定的节点。 </p><ol start="2"><li>平衡（rebalance）slot ：</li></ol><p>1）平衡集群中各个节点的slot数量</p><p><code>redis-cli -a cc --cluster rebalance 192.168.163.132:6379</code></p><p>2）根据集群中各个节点设置的权重等平衡slot数量（不执行，只模拟）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a cc --cluster rebalance --cluster-weight 117457eab5071954faab5e81c3170600d5192270=5 815da8448f5d5a304df0353ca10d8f9b77016b28=4 56005b9413cbf225783906307a2631109e753f8f=3 --cluster-simulate 192.168.163.132:6379</span><br></pre></td></tr></table></figure><ol start="3"><li>导入集群</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster import 192.168.163.132:6379 --cluster-from 192.168.163.132:9021 --cluster-replace</span><br></pre></td></tr></table></figure><p>说明：外部Redis实例（9021）导入到集群中的任意一节点。</p><p>注意：测试下来发现参数–cluster-replace没有用，如果集群中已经包含了某个key，在导入的时候会失败，不会覆盖，只有清空集群key才能导入。</p><p>并且发现如果集群设置了密码，也会导入失败，需要设置集群密码为空才能进行导入（call）。通过monitor（9021）的时候发现，在migrate的时候需要密码进行auth认证。 </p><p>总结：Redis Cluster 通过redis-cli –cluster来创建和管理集群的方式和 redis-trib.rb脚本绝大部分都是一样的，所以对于比较熟悉 redis-trib.rb 脚本的，使用–cluster也非常顺手。</p><p>参考：<a href="https://www.cnblogs.com/zhoujinyi/p/11606935.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhoujinyi/p/11606935.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis-5-0-redis-cli-–cluster-help说明&quot;&gt;&lt;a href=&quot;#Redis-5-0-redis-cli-–cluster-help说明&quot; class=&quot;headerlink&quot; title=&quot;Redis 5.0 redis-cli –c
      
    
    </summary>
    
      <category term="Redis" scheme="http://macintosh-c.coding.me/categories/Redis/"/>
    
    
      <category term="Redis Cluster" scheme="http://macintosh-c.coding.me/tags/Redis-Cluster/"/>
    
  </entry>
  
  <entry>
    <title>Redis 持久化存储</title>
    <link href="http://macintosh-c.coding.me/2021/05/12/Databases/Redis/Redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>http://macintosh-c.coding.me/2021/05/12/Databases/Redis/Redis持久化/</id>
    <published>2021-05-12T04:20:29.000Z</published>
    <updated>2021-05-14T06:07:56.859Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis-持久化存储"><a href="#Redis-持久化存储" class="headerlink" title="Redis 持久化存储"></a>Redis 持久化存储</h2><p>Redis的数据回写机制</p><p>Redis的数据回写机制分同步和异步两种，</p><ol><li>同步回写即SAVE命令，主进程直接向磁盘回写数据。在数据大的情况下会导致系统假死很长时间，所以一般不是推荐的。</li><li>异步回写即BGSAVE命令，主进程fork后，复制自身并通过这个新的进程回写磁盘，回写结束后新进程自行关闭。由于这样做不需要主进程阻塞，系统不会假死，一般默认会采用这个方法。</li></ol><p>Redis持久化的方式有两种： RDB 和 AOF</p><p>首先，我们应该明确持久化的数据有什么用，答案是用于重启后的数据恢复。<br>Redis是一个内存数据库，无论是RDB还是AOF，都只是其保证数据恢复的措施。<br>所以Redis在利用RDB和AOF进行恢复的时候，都会读取RDB或AOF文件，重新加载到内存中。</p><p>RDB就是Snapshot快照存储，是默认的持久化方式。<br>可理解为半持久化模式，即按照一定的策略周期性的将数据保存到磁盘。<br>对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。<br>下面是默认的快照设置：</p><p>save 900 1    #当有一条Keys数据被改变时，900秒刷新到Disk一次<br>save 300 10   #当有10条Keys数据被改变时，300秒刷新到Disk一次<br>save 60 10000 #当有10000条Keys数据被改变时，60秒刷新到Disk一次</p><p>Redis的RDB文件不会坏掉，因为其写操作是在一个新进程中进行的。<br>当生成一个新的RDB文件时，Redis生成的子进程会先将数据写到一个临时文件中，然后通过原子性rename系统调用将临时文件重命名为RDB文件。<br>这样在任何时候出现故障，Redis的RDB文件都总是可用的。</p><p>同时，Redis的RDB文件也是Redis主从同步内部实现中的一环。<br>第一次Slave向Master同步的实现是：<br>Slave向Master发出同步请求，Master先dump出rdb文件，然后将rdb文件全量传输给slave，然后Master把缓存的命令转发给Slave，初次同步完成。</p><p>第二次以及以后的同步实现是：<br>Master将变量的快照直接实时依次发送给各个Slave。<br>但不管什么原因导致Slave和Master断开重连都会重复以上两个步骤的过程。<br>Redis的主从复制是建立在内存快照的持久化基础上的，只要有Slave就一定会有内存快照发生。</p><p>可以很明显的看到，RDB有它的不足，就是一旦数据库出现问题，那么我们的RDB文件中保存的数据并不是全新的。<br>从上次RDB文件生成到Redis停机这段时间的数据全部丢掉了。</p><p>AOF(Append-Only File)比RDB方式有更好的持久化性。<br>由于在使用AOF持久化方式时，Redis会将每一个收到的写命令都通过Write函数追加到文件中，类似于MySQL的binlog。<br>当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。</p><p>对应的设置参数为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vim /opt/redis/etc/redis_6379.conf</span><br><span class="line"></span><br><span class="line">appendonly yes       #启用AOF持久化方式</span><br><span class="line">appendfilename appendonly.aof #AOF文件的名称，默认为appendonly.aof</span><br><span class="line"># appendfsync always #每次收到写命令就立即强制写入磁盘，是最有保证的完全的持久化，但速度也是最慢的，一般不推荐使用。</span><br><span class="line">appendfsync everysec #每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，是受推荐的方式。</span><br><span class="line"># appendfsync no     #完全依赖OS的写入，一般为30秒左右一次，性能最好但是持久化最没有保证，不被推荐。</span><br></pre></td></tr></table></figure></p><p>AOF的完全持久化方式同时也带来了另一个问题，持久化文件会变得越来越大。<br>比如我们调用INCR test命令100次，文件中就必须保存全部的100条命令，但其实99条都是多余的。<br>因为要恢复数据库的状态其实文件中保存一条SET test 100就够了。<br>为了压缩AOF的持久化文件，Redis提供了bgrewriteaof命令。<br>收到此命令后Redis将使用与快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的文件，以此来实现控制AOF文件的增长。<br>由于是模拟快照的过程，因此在重写AOF文件时并没有读取旧的AOF文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的AOF文件。</p><p>对应的设置参数为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vim /opt/redis/etc/redis_6379.conf</span><br><span class="line"></span><br><span class="line">no-appendfsync-on-rewrite yes   #在日志重写时，不进行命令追加操作，而只是将其放在缓冲区里，避免与命令的追加造成DISK IO上的冲突。</span><br><span class="line">auto-aof-rewrite-percentage 100 #当前AOF文件大小是上次日志重写得到AOF文件大小的二倍时，自动启动新的日志重写过程。</span><br><span class="line">auto-aof-rewrite-min-size 64mb  #当前AOF文件启动新的日志重写过程的最小值，避免刚刚启动Reids时由于文件尺寸较小导致频繁的重写。</span><br></pre></td></tr></table></figure><p>到底选择什么呢？下面是来自官方的建议：</p><p>常，如果你要想提供很高的数据保障性，那么建议你同时使用两种持久化方式。<br>如果你可以接受灾难带来的几分钟的数据丢失，那么你可以仅使用RDB。<br>很多用户仅使用了AOF，但是我们建议，既然RDB可以时不时的给数据做个完整的快照，并且提供更快的重启，所以最好还是也使用RDB。<br>因此，我们希望可以在未来（长远计划）统一AOF和RDB成一种持久化模式。</p><p>在数据恢复方面：</p><p>RDB的启动时间会更短，原因有两个：<br>一是RDB文件中每一条数据只有一条记录，不会像AOF日志那样可能有一条数据的多次操作记录。所以每条数据只需要写一次就行了。<br>另一个原因是RDB文件的存储格式和Redis数据在内存中的编码格式是一致的，不需要再进行数据编码工作，所以在CPU消耗上要远小于AOF日志的加载。</p><p>实际上，当Redis服务器挂掉时，重启时将按照以下优先级恢复数据到内存：</p><ol><li>如果只配置AOF,重启时加载AOF文件恢复数据；</li><li>如果同时 配置了RDB和AOF,启动是只加载AOF文件恢复数据;</li><li>如果只配置RDB,启动是将加载dump文件恢复数据。</li></ol><p>也就是说，AOF的优先级要高于RDB，这也很好理解，因为AOF本身对数据的完整性保障要高于RDB。</p><p>但在我们目前的线上环境中，由于数据都设置有过期时间，采用AOF的方式会不太实用，过于频繁的写操作会使AOF文件增长到异常的庞大，大大超过了我们实际的数据量，这也会导致在进行数据恢复时耗用大量的时间。</p><p>因此，可以在Slave上仅开启Snapshot来进行本地化，同时可以考虑将save中的频率调高一些或者调用一个计划任务来进行定期bgsave的快照存储，来尽可能的保障本地化数据的完整性。<br>在这样的架构下，如果仅仅是Master挂掉，Slave完整，数据恢复可达到100%。</p><p>如果Master与Slave同时挂掉的话，数据的恢复也可以达到一个可接受的程度。</p><p>参考：<a href="https://blog.csdn.net/jack85986370/article/details/51453041?utm_term=redis集群rdb文件&amp;utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~sobaiduweb~default-1-51453041&amp;spm=3001.4430" target="_blank" rel="noopener">https://blog.csdn.net/jack85986370/article/details/51453041?utm_term=redis集群rdb文件&amp;utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~sobaiduweb~default-1-51453041&amp;spm=3001.4430</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis-持久化存储&quot;&gt;&lt;a href=&quot;#Redis-持久化存储&quot; class=&quot;headerlink&quot; title=&quot;Redis 持久化存储&quot;&gt;&lt;/a&gt;Redis 持久化存储&lt;/h2&gt;&lt;p&gt;Redis的数据回写机制&lt;/p&gt;
&lt;p&gt;Redis的数据回写机制分同
      
    
    </summary>
    
      <category term="Redis" scheme="http://macintosh-c.coding.me/categories/Redis/"/>
    
    
      <category term="Redis 持久化存储" scheme="http://macintosh-c.coding.me/tags/Redis-%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>YApi  使用教程</title>
    <link href="http://macintosh-c.coding.me/2021/05/10/YApi/YApi%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <id>http://macintosh-c.coding.me/2021/05/10/YApi/YApi使用教程/</id>
    <published>2021-05-10T01:56:56.000Z</published>
    <updated>2021-05-10T02:28:30.343Z</updated>
    
    <content type="html"><![CDATA[<h2 id="YApi-使用教程"><a href="#YApi-使用教程" class="headerlink" title="YApi  使用教程"></a>YApi  使用教程</h2><p>推荐一个好用的接口管理平台，YApi，集postman调试接口功能于一体，免去了从0手写接口文档的痛苦</p><h3 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h3><h4 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h4><p>前往nodejs官网，直接下载安装就行。</p><h4 id="安装MongoDB安装略"><a href="#安装MongoDB安装略" class="headerlink" title="安装MongoDB安装略"></a>安装MongoDB安装略</h4><p>MongoDB安装过程略，自行解决</p><p>打开navicat，新建链接，新安装的MongoDB应该是没有密码，所以不需要Authentication。MongoDB的端口默认是27017，确认连通性没有问题。</p><h4 id="安装yapi"><a href="#安装yapi" class="headerlink" title="安装yapi"></a>安装yapi</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install -g yapi-cli --registry https://registry.npm.taobao.org</span><br><span class="line">yapi server</span><br></pre></td></tr></table></figure><p>控制台会提示:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yapi server</span><br><span class="line">在浏览器打开 http://0.0.0.0:9090 访问。非本地服务器，请将 0.0.0.0 替换成指定的域名或ip</span><br></pre></td></tr></table></figure></p><p>打开地址，出现安装页面，选择需要安装的版本，填写完表格，点击开始部署。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">初始化管理员账号成功,账号名：&quot;******&quot;，密码：&quot;ymfe.org&quot;</span><br><span class="line">部署成功，请切换到部署目录，输入： &quot;node vendors/server/app.js&quot; 指令启动服务器, 然后在浏览器打开 http://127.0.0.1:3000 访问</span><br></pre></td></tr></table></figure><p>安装完了就有上面的提示了，可关闭当前的终端，按照提示继续操作。切换到安装目录，把命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node vendors/server/app.js</span><br></pre></td></tr></table></figure><p>复制到命令行，启动服务。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ node vendors/server/app.js</span><br><span class="line">log: -------------------------------------swaggerSyncUtils constructor-----------------------------------------------</span><br><span class="line">log: 服务已启动，请打开下面链接访问:</span><br><span class="line">http://127.0.0.1:3000/</span><br><span class="line">log: mongodb load success...</span><br></pre></td></tr></table></figure></p><p>打开地址访问，应该就好使了。</p><h4 id="配置后台启动"><a href="#配置后台启动" class="headerlink" title="配置后台启动"></a>配置后台启动</h4><p>上述步骤安装完，终端是不能关闭的，需要设置服务成后台启动，方法多样。</p><p>编辑这个文件，在文件里加入一个函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br><span class="line"></span><br><span class="line">function startyapi &#123;</span><br><span class="line">  cd /Volumes/Work/my-yapi</span><br><span class="line">  nohup node vendors/server/app.js &amp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>使用:wq保存，在控制台使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure></p><p>使刚才的改动生效。</p><p>在控制台输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">startyapi</span><br><span class="line"></span><br><span class="line">$ startyapi</span><br><span class="line">[2] 78163</span><br><span class="line">appending output to nohup.out</span><br></pre></td></tr></table></figure></p><p>可以看到已经在后台启动了。</p><p>如果想要关闭服务，可以使用lsof来查看端口占用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lsof -i tcp:3000</span><br><span class="line"></span><br><span class="line">$ lsof -i tcp:3000</span><br><span class="line">COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME</span><br><span class="line">node    78163  hlp   22u  IPv6 0x673f644c16150d2d      0t0  TCP *:hbci (LISTEN)</span><br></pre></td></tr></table></figure></p><p>使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo kill 78163 #这里是你具体查出来的PID</span><br></pre></td></tr></table></figure></p><p>来结束进程，就关闭了yapi的服务。</p><h3 id="YApi使用"><a href="#YApi使用" class="headerlink" title="YApi使用"></a>YApi使用</h3><p>具体的使用详情可参考官方文档，这里记录几点自我使用总结发现的优秀点。</p><ol><li>可自由数据导入与导出，且支持postman，可与postman互通。</li><li>导出功能支持可选择公开接口导出。导出的接口文档样式也比较灵活，可在接口的编辑的备注里去自由的添加一些针对该接口的说明，且支持markdown编辑。也可通过Wiki来添加全局的说明。</li><li>可以如postman那样自由切换配置环境，调试接口脚本。</li><li>可项目成员管理，且工作空间以及项目权限可自由设置。</li><li>可接口动态实时查看。</li><li>分分钟MOCK测试数据。</li><li>接口自动化测试。</li></ol><p>参考：<a href="https://zhuanlan.zhihu.com/p/94297858" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/94297858</a><br>官网教程：<a href="https://hellosean1025.github.io/yapi/documents/index.html" target="_blank" rel="noopener">https://hellosean1025.github.io/yapi/documents/index.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;YApi-使用教程&quot;&gt;&lt;a href=&quot;#YApi-使用教程&quot; class=&quot;headerlink&quot; title=&quot;YApi  使用教程&quot;&gt;&lt;/a&gt;YApi  使用教程&lt;/h2&gt;&lt;p&gt;推荐一个好用的接口管理平台，YApi，集postman调试接口功能于一体，免去了
      
    
    </summary>
    
      <category term="YApi" scheme="http://macintosh-c.coding.me/categories/YApi/"/>
    
    
      <category term="YApi学习" scheme="http://macintosh-c.coding.me/tags/YApi%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>sftp常用命令介绍</title>
    <link href="http://macintosh-c.coding.me/2021/05/07/Linux/sftp%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BB%8B%E7%BB%8D/"/>
    <id>http://macintosh-c.coding.me/2021/05/07/Linux/sftp常用命令介绍/</id>
    <published>2021-05-07T05:56:56.000Z</published>
    <updated>2021-05-07T03:22:22.199Z</updated>
    
    <content type="html"><![CDATA[<h3 id="sftp常用命令介绍"><a href="#sftp常用命令介绍" class="headerlink" title="sftp常用命令介绍"></a>sftp常用命令介绍</h3><blockquote><p>sftp是Secure FileTransferProtocol的缩写，安全文件传送协议。可以为传输文件提供一种安全的加密方法。sftp与 ftp有着几乎一样的语法和功能。SFTP为 SSH的一部分，是一种传输档案至Blogger伺服器的安全方式。其实在SSH软件包中，已经包含了一个叫作SFTP(Secure File TransferProtocol)的安全文件传输子系统，SFTP本身没有单独的守护进程，它必须使用sshd守护进程（端口号默认是22）来完成相应的连接操作，所以从某种意义上来说，SFTP并不像一个服务器程序，而更像是一个客户端程序。SFTP同样是使用加密传输认证信息和传输的数据，所以，使用SFTP是非常安全的。但是，由于这种传输方式使用了加密/解密技术，所以传输效率比普通的FTP要低得多，如果您对网络安全性要求更高时，可以使用SFTP代替FTP。</p></blockquote><ol><li><p>sftp user@ip</p><pre><code>你要用sftp, 当然得登录到sftp服务器啊， 在linux的shell中执行上面的命令后， linux shell会提示用户输入密码， 我们就输入password吧。 这样就成功建立了sftp连接。</code></pre></li><li><p>help</p><pre><code>建立连接后， linux shell中的$编程了sftp&gt;,  这也对。 现在执行以下help, 可以看看sftp支持哪些命令。</code></pre></li><li><p>pwd和lpwd</p><pre><code>pwd是看远端服务器的目录， 即sftp服务器默认的当前目录。  lpwd是看linux本地目录。</code></pre></li><li><p>ls和lls</p><pre><code>ls是看sftp服务器下当前目录下的东东， lls是看linux当前目录下的东东。</code></pre></li><li><p>put a.txt</p><pre><code>这个是把linux当前目录下的a.txt文件上传到sftp服务器的当前目录下。</code></pre></li><li><p>get b.txt</p><pre><code>这个是把sftp服务器当前目录下的b.txt文件下载到linux当前目录下。  </code></pre></li><li><p>!command</p><pre><code>这个是指在linux上执行command这个命令， 比如!ls是列举linux当前目录下的东东， !rm a.txt是删除linux当前目录下的a.txt文件。这个命令非常非常有用， 因为在sftp&gt; 后输入命令， 默认值针对sftp服务器的， 所以执行rm a.txt删除的是sftp服务器上的a.txt文件， 而非本地的linux上的a.txt文件。</code></pre></li><li><p>exit和quit</p><pre><code>退出。</code></pre></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;sftp常用命令介绍&quot;&gt;&lt;a href=&quot;#sftp常用命令介绍&quot; class=&quot;headerlink&quot; title=&quot;sftp常用命令介绍&quot;&gt;&lt;/a&gt;sftp常用命令介绍&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;sftp是Secure FileTransferP
      
    
    </summary>
    
      <category term="sftp" scheme="http://macintosh-c.coding.me/categories/sftp/"/>
    
    
      <category term="sftp" scheme="http://macintosh-c.coding.me/tags/sftp/"/>
    
  </entry>
  
  <entry>
    <title>Couchbase 数据迁移</title>
    <link href="http://macintosh-c.coding.me/2021/05/07/Databases/couchbase/couchbase%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
    <id>http://macintosh-c.coding.me/2021/05/07/Databases/couchbase/couchbase数据同步/</id>
    <published>2021-05-07T04:49:36.000Z</published>
    <updated>2021-05-07T02:47:29.113Z</updated>
    
    <content type="html"><![CDATA[<p>今日碰到需要迁移couchbase数据的需求，做了相关调研，记录如下：</p><h2 id="方案1-备份与恢复"><a href="#方案1-备份与恢复" class="headerlink" title="方案1:备份与恢复"></a>方案1:备份与恢复</h2><h4 id="cbback"><a href="#cbback" class="headerlink" title="cbback"></a>cbback</h4><blockquote><p>cbbackup 工具 是一个灵活的备份命令，使您可以备份本地数据和远程节点和涉及您的集群数据的不同组合：<br>单节点单buckets<br>单节点上所有buckets<br>整个群集上单个buckets<br>整个群集上所有buckets</p></blockquote><h6 id="cbbackup-命令参数选项"><a href="#cbbackup-命令参数选项" class="headerlink" title="cbbackup 命令参数选项:"></a>cbbackup 命令参数选项:</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cbbackup [options] [source] [backup_dir]</span><br></pre></td></tr></table></figure><p>Options:用来配置连接群集的用户和密码信息，备份类型和bucket 选项</p><ul><li>–single-node:备份单节点</li><li>–bucket-source or -b:备份特定名称的 bucket</li></ul><p>Source:本地数据目录参考或者是远程 节点/群集规范</p><ul><li><p>本地目录参考:本地目录规范是使用 <code>couchstore-files</code> 协议定义的 URL。举个栗子：<br>couchstore-files:///opt/couchbase/var/lib/couchbase/data/default</p><ul><li>使用这种方法，您只需在单个节点上备份指定 bucket 的数据。如果在群集上备份全部 bucket 数据 或是 备份单个节点上的所有数据，这时你必须使用群集节点规范。这种方法在 bucket 中定义的设计文档不支持。</li></ul></li><li><p>群集 节点:这个一个节点或是群集中的一个节点，将 URL 指定为一个节点 或是 群集 服务。举个栗子:  </p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">http://HOST:8091</span><br><span class="line"></span><br><span class="line">// For distinction you can use the couchbase protocol prefix:</span><br><span class="line">    couchbase://HOST:8091</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// The administrator and password can also be combined with both forms of the URL for authentication. </span><br><span class="line">If you have named data buckets (other than the default bucket) that you want to backup, </span><br><span class="line">specify an administrative name and password for the bucket:</span><br><span class="line"></span><br><span class="line">    couchbase://Administrator:password@HOST:8091</span><br></pre></td></tr></table></figure><p>Backup_dir:执行 cbbackup 命令保存备份数据的目录</p><ul><li>这必须是一个绝对明确的目录，文件将直接存储在特定的目录；</li></ul><h6 id="下面提供一些不同数据组合的例子："><a href="#下面提供一些不同数据组合的例子：" class="headerlink" title="下面提供一些不同数据组合的例子："></a>下面提供一些不同数据组合的例子：</h6><ol><li>备份所有节点上的所有bucket</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cbbackup http://HOST:8091 /backups/backup-20120501 \ </span><br><span class="line">    -u Administrator -p password</span><br></pre></td></tr></table></figure><ol start="2"><li>备份所有节点上的指定的bucket</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cbbackup http://HOST:8091 /backups/backup-20120501 \</span><br><span class="line">    -u Administrator -p password \</span><br><span class="line">    -b default</span><br></pre></td></tr></table></figure><ol start="3"><li>备份单个节点 所有bucket</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cbbackup http://HOST:8091 /backups/backup-20120501 \</span><br><span class="line">      -u Administrator -p password \</span><br><span class="line">      --single-node</span><br></pre></td></tr></table></figure><ol start="4"><li>备份单个节点 单个bucket</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cbbackup http://HOST:8091 /backups/backup-20120501 \</span><br><span class="line">      -u Administrator -p password \</span><br><span class="line">      --single-node \</span><br><span class="line">      -b default</span><br></pre></td></tr></table></figure><p>5.在备份的时候过滤 Keys(以正则表达式的形式体现)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cbbackup http://HOST:8091 /backups/backup-20120501 \</span><br><span class="line">  -u Administrator -p password \</span><br><span class="line">  -b default \</span><br><span class="line">  -k &apos;^object.*&apos;</span><br></pre></td></tr></table></figure><blockquote><p>参考：<a href="https://blog.csdn.net/weixin_34161032/article/details/91728682" target="_blank" rel="noopener">https://blog.csdn.net/weixin_34161032/article/details/91728682</a></p></blockquote><h4 id="cbrestore"><a href="#cbrestore" class="headerlink" title="cbrestore"></a>cbrestore</h4><h6 id="cbrestore-命令参数选项"><a href="#cbrestore-命令参数选项" class="headerlink" title="cbrestore 命令参数选项"></a>cbrestore 命令参数选项</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cbrestore   [options]  [source]  [destination]</span><br></pre></td></tr></table></figure><blockquote><p>cbrestore 命令一次只能恢复一个单独的bucket的数据。如果你备份了这个群集的bucket，则必须还原每个bucket到集群。所有目的bucket必须已经存在，因为 cbrestore 不会帮你要恢复的节点中创建配置bucket。</p></blockquote><ol><li>恢复一个单独的bucket 到群集中去：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cbrestore \</span><br><span class="line">    /backups/backup-2012-05-10 \</span><br><span class="line">    http://Administrator:password@HOST:8091 \</span><br><span class="line">    --bucket-source=XXX</span><br></pre></td></tr></table></figure><ol start="2"><li>恢复bucket 到 群集中不同的 bucket 中：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cbrestore \</span><br><span class="line">    /backups/backup-2012-05-10 \</span><br><span class="line">    http://Administrator:password@HOST:8091 \</span><br><span class="line">    --bucket-source=XXX \</span><br><span class="line">    --bucket-destination=YYY</span><br></pre></td></tr></table></figure><ol start="3"><li>在恢复的时候过滤 key<br>将以object开头的key的数据还原到一个bucket中：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cbrestore /backups/backup-20120501 http://HOST:8091 \</span><br><span class="line">    -u Administrator -p password \</span><br><span class="line">    -b default \</span><br><span class="line">    -k &apos;^object.*&apos;</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>参考：<a href="http://suzf.net/thread-0902-1067.html" target="_blank" rel="noopener">http://suzf.net/thread-0902-1067.html</a></p></blockquote><h4 id="增量备份（亲测未达到预期）"><a href="#增量备份（亲测未达到预期）" class="headerlink" title="增量备份（亲测未达到预期）"></a>增量备份（亲测未达到预期）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cbbackup -m diff</span><br></pre></td></tr></table></figure><blockquote><p>参考：<a href="https://docs.couchbase.com/server/current/backup-restore/incremental-backup.html" target="_blank" rel="noopener">https://docs.couchbase.com/server/current/backup-restore/incremental-backup.html</a></p></blockquote><h2 id="方案2-XDCR跨集群复制"><a href="#方案2-XDCR跨集群复制" class="headerlink" title="方案2:XDCR跨集群复制"></a>方案2:XDCR跨集群复制</h2><blockquote><p>XDCR提供了多个有效vbucket的数据的复制，主要用于跨数据中心的多集群间的复制，可以跨版本复制。</p></blockquote><p>couchbase 界面 XDCR下 创建集群引用和复制，操作如下：<br><img src="/img/couchbase/1.png" alt="image"><br><img src="/img/couchbase/2.png" alt="image"><br><img src="/img/couchbase/3.png" alt="image"></p><blockquote><p>参考：<a href="https://blog.51cto.com/lhrbest/2690216" target="_blank" rel="noopener">https://blog.51cto.com/lhrbest/2690216</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今日碰到需要迁移couchbase数据的需求，做了相关调研，记录如下：&lt;/p&gt;
&lt;h2 id=&quot;方案1-备份与恢复&quot;&gt;&lt;a href=&quot;#方案1-备份与恢复&quot; class=&quot;headerlink&quot; title=&quot;方案1:备份与恢复&quot;&gt;&lt;/a&gt;方案1:备份与恢复&lt;/h2&gt;&lt;h
      
    
    </summary>
    
      <category term="Couchbase" scheme="http://macintosh-c.coding.me/categories/Couchbase/"/>
    
    
      <category term="Couchbase数据迁移" scheme="http://macintosh-c.coding.me/tags/Couchbase%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/"/>
    
  </entry>
  
  <entry>
    <title>Nacos &amp; Sentinel</title>
    <link href="http://macintosh-c.coding.me/2021/04/01/spring/SpringCloudAlibaba/nacos&amp;sentinel/"/>
    <id>http://macintosh-c.coding.me/2021/04/01/spring/SpringCloudAlibaba/nacos&amp;sentinel/</id>
    <published>2021-03-31T20:37:05.000Z</published>
    <updated>2021-04-02T02:43:35.685Z</updated>
    
    <content type="html"><![CDATA[<h2 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h2><blockquote><p><a href="https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E" target="_blank" rel="noopener">https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E</a></p></blockquote><h2 id="相关地址"><a href="#相关地址" class="headerlink" title="相关地址"></a>相关地址</h2><p>spring-cloud-alibaba：</p><blockquote><p><a href="https://github.com/Macintosh-c/spring-cloud-alibaba" target="_blank" rel="noopener">https://github.com/Macintosh-c/spring-cloud-alibaba</a></p></blockquote><p>nacos：</p><blockquote><p><a href="https://github.com/Macintosh-c/nacos" target="_blank" rel="noopener">https://github.com/Macintosh-c/nacos</a></p></blockquote><p>Sentinel：</p><blockquote><p><a href="https://github.com/Macintosh-c/Sentinel" target="_blank" rel="noopener">https://github.com/Macintosh-c/Sentinel</a></p></blockquote><h2 id="blog："><a href="#blog：" class="headerlink" title="blog："></a>blog：</h2><blockquote><p><a href="https://blog.didispace.com/spring-cloud-learning/" target="_blank" rel="noopener">https://blog.didispace.com/spring-cloud-learning/</a><br><a href="https://www.jianshu.com/p/9a8d94c0c90c" target="_blank" rel="noopener">https://www.jianshu.com/p/9a8d94c0c90c</a><br><a href="https://blog.csdn.net/enjoyedu/category_10498794.html" target="_blank" rel="noopener">https://blog.csdn.net/enjoyedu/category_10498794.html</a></p></blockquote><h2 id="一-Nacos部署"><a href="#一-Nacos部署" class="headerlink" title="一.Nacos部署"></a>一.Nacos部署</h2><p>持久化:</p><blockquote><p><a href="https://blog.didispace.com/spring-cloud-alibaba-4/" target="_blank" rel="noopener">https://blog.didispace.com/spring-cloud-alibaba-4/</a></p></blockquote><p>集群搭建：</p><blockquote><p><a href="https://blog.didispace.com/spring-cloud-alibaba-5/" target="_blank" rel="noopener">https://blog.didispace.com/spring-cloud-alibaba-5/</a></p></blockquote><p>Nacos 依赖 Java 环境来运行。如果你是从代码开始构建并运行Nacos，还需要为此配置Maven环境，请确保是在以下版本环境中安装使用:</p><p>64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。</p><p>64 bit JDK 1.8+</p><p>Maven 3.2.x+</p><h3 id="1-下载并安装"><a href="#1-下载并安装" class="headerlink" title="1.下载并安装"></a>1.下载并安装</h3><h4 id="1-下载源码"><a href="#1-下载源码" class="headerlink" title="1)下载源码"></a>1)下载源码</h4><p>git clone <a href="https://github.com/alibaba/nacos.git" target="_blank" rel="noopener">https://github.com/alibaba/nacos.git</a></p><p>注意：默认为develop分支，需要切换到对应的版本分支</p><h4 id="2-安装到本地仓库"><a href="#2-安装到本地仓库" class="headerlink" title="2)安装到本地仓库"></a>2)安装到本地仓库</h4><p>cd nacos/</p><p>mvn -Prelease-nacos -Dmaven.test.skip=true clean install -U </p><h4 id="3-启动Nacos"><a href="#3-启动Nacos" class="headerlink" title="3)启动Nacos"></a>3)启动Nacos</h4><p>cd distribution/target/nacos-server-$version/nacos/bin</p><ul><li>Linux</li></ul><p>./startup.sh -m standalone</p><ul><li>Windows</li></ul><p>startup.cmd</p><h4 id="4-访问服务"><a href="#4-访问服务" class="headerlink" title="4)访问服务"></a>4)访问服务</h4><p>打开浏览器访问：<a href="http://localhost:8848/nacos" target="_blank" rel="noopener">http://localhost:8848/nacos</a></p><p>注：从 0.8.0 版本开始，需要登录才可访问，默认账号密码为 nacos/nacos</p><h4 id="5-参考："><a href="#5-参考：" class="headerlink" title="5)参考："></a>5)参考：</h4><blockquote><p><a href="https://www.jianshu.com/p/9a8d94c0c90c" target="_blank" rel="noopener">https://www.jianshu.com/p/9a8d94c0c90c</a></p></blockquote><h2 id="二-Sentinel-控制台"><a href="#二-Sentinel-控制台" class="headerlink" title="二.Sentinel 控制台"></a>二.Sentinel 控制台</h2><h3 id="1-下载编译"><a href="#1-下载编译" class="headerlink" title="1.下载编译"></a>1.下载编译</h3><p>git clone <a href="https://github.com/alibaba/Sentinel.git" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel.git</a></p><p>注意：需要切换到对应的版本分支</p><p>mvn clean package</p><h3 id="2-启动控制台"><a href="#2-启动控制台" class="headerlink" title="2.启动控制台"></a>2.启动控制台</h3><p>Sentinel 控制台是一个标准的 SpringBoot 应用，以 SpringBoot 的方式运行 jar 包即可。</p><p>cd sentinel-dashboard\target</p><p>java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">java -Dserver.port=8480 -Dcsp.sentinel.dashboard.server=localhost:8480 -Dproject.name=sentinel-dashboard -Dsentinel.dashboard.auth.username=sentinel -Dsentinel.dashboard.auth.password=123456 -jar sentinel-dashboard-1.7.2.jar</span><br><span class="line">-Dserver.port=8480 # 指定控制台的端口为8480</span><br><span class="line">-Dcsp.sentinel.dashboard.server=localhost:8480 # 指定要被哪个控制台监控（这里指定的是自己监控自己）</span><br><span class="line">-Dproject.name=sentinel-dashboard # 指定实例名称（名称会在控制台左侧以菜单显示）</span><br><span class="line">-Dsentinel.dashboard.auth.username=sentinel # 设置登录的帐号为：sentinel</span><br><span class="line">-Dsentinel.dashboard.auth.password=123456 # 设置登录的密码为：123456</span><br></pre></td></tr></table></figure><p>如果8080端口冲突请修改-Dserver.port=自定义端口号</p><h3 id="3-访问服务-默认的登录帐号和密码都是：sentinel"><a href="#3-访问服务-默认的登录帐号和密码都是：sentinel" class="headerlink" title="3.访问服务 默认的登录帐号和密码都是：sentinel"></a>3.访问服务 默认的登录帐号和密码都是：sentinel</h3><p>打开浏览器访问：<a href="http://localhost:8080/#/dashboard/home" target="_blank" rel="noopener">http://localhost:8080/#/dashboard/home</a></p><h2 id="三-学习知识点总结"><a href="#三-学习知识点总结" class="headerlink" title="三.学习知识点总结:"></a>三.学习知识点总结:</h2><h3 id="1-Nacos-配置中心"><a href="#1-Nacos-配置中心" class="headerlink" title="1.Nacos 配置中心"></a>1.Nacos 配置中心</h3><h4 id="1-区分不同环境"><a href="#1-区分不同环境" class="headerlink" title="1)区分不同环境"></a>1)区分不同环境</h4><ul><li>profile</li><li>group id</li><li>namespace<h4 id="2-持久化到外部mysql"><a href="#2-持久化到外部mysql" class="headerlink" title="2)持久化到外部mysql"></a>2)持久化到外部mysql</h4><h4 id="3-集群化部署"><a href="#3-集群化部署" class="headerlink" title="3)集群化部署"></a>3)集群化部署</h4></li></ul><h3 id="2-Sentinel"><a href="#2-Sentinel" class="headerlink" title="2.Sentinel"></a>2.Sentinel</h3><blockquote><p><a href="https://github.com/Macintosh-c/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-examples/sentinel-example/sentinel-core-example/readme-zh.md" target="_blank" rel="noopener">https://github.com/Macintosh-c/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-examples/sentinel-example/sentinel-core-example/readme-zh.md</a></p></blockquote><h4 id="1-自定义限流处理逻辑"><a href="#1-自定义限流处理逻辑" class="headerlink" title="1)自定义限流处理逻辑"></a>1)自定义限流处理逻辑</h4><ul><li>默认限流异常处理</li><li>使用 @SentinelResource 注解下的限流异常处理</li></ul><h4 id="2-动态规则扩展"><a href="#2-动态规则扩展" class="headerlink" title="2)动态规则扩展"></a>2)动态规则扩展</h4><ul><li>文件配置</li><li>Nacos配置</li><li>ZooKeeper配置</li><li>Apollo配置<blockquote><p><a href="https://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95#datasource-%E6%89%A9%E5%B1%95" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95#datasource-%E6%89%A9%E5%B1%95</a></p></blockquote></li></ul><h4 id="3-使用Nacos存储规则"><a href="#3-使用Nacos存储规则" class="headerlink" title="3)使用Nacos存储规则"></a>3)使用Nacos存储规则</h4><blockquote><p><a href="https://blog.didispace.com/spring-cloud-alibaba-sentinel-2-1/" target="_blank" rel="noopener">https://blog.didispace.com/spring-cloud-alibaba-sentinel-2-1/</a></p></blockquote><h4 id="4-各种规则理解与配置"><a href="#4-各种规则理解与配置" class="headerlink" title="4)各种规则理解与配置"></a>4)各种规则理解与配置</h4><ul><li>流控规则  flowrule</li><li>降级规则  degraderrule</li><li>热点规则  param-flow</li><li>系统规则  system</li><li>授权规则  authority<blockquote><p><a href="https://blog.csdn.net/enjoyedu/category_10498794.html" target="_blank" rel="noopener">https://blog.csdn.net/enjoyedu/category_10498794.html</a></p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;版本说明&quot;&gt;&lt;a href=&quot;#版本说明&quot; class=&quot;headerlink&quot; title=&quot;版本说明&quot;&gt;&lt;/a&gt;版本说明&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/alibaba/spring-cloud-
      
    
    </summary>
    
      <category term="Spring Cloud Alibaba" scheme="http://macintosh-c.coding.me/categories/Spring-Cloud-Alibaba/"/>
    
    
      <category term="Spring Cloud Alibaba" scheme="http://macintosh-c.coding.me/tags/Spring-Cloud-Alibaba/"/>
    
  </entry>
  
  <entry>
    <title>Linux top命令详解</title>
    <link href="http://macintosh-c.coding.me/2021/03/05/Linux/top%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>http://macintosh-c.coding.me/2021/03/05/Linux/top命令详解/</id>
    <published>2021-03-05T05:56:56.000Z</published>
    <updated>2021-03-08T01:55:30.344Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Linux-top命令详解"><a href="#Linux-top命令详解" class="headerlink" title="Linux top命令详解"></a>Linux top命令详解</h3><p>top命令经常用来监控<a href="http://lib.csdn.net/base/linux" target="_blank" rel="noopener">Linux</a>的系统状况，比如cpu、内存的使用</p><p><img src="/img/Linux/1.jpg" alt="image"></p><h5 id="1-1-系统运行时间和平均负载："><a href="#1-1-系统运行时间和平均负载：" class="headerlink" title="1.1 系统运行时间和平均负载："></a>1.1 系统运行时间和平均负载：</h5><p><code>top - 09:40:41 up 2 days, 15:45,  2 users,  load average: 0.25, 0.41, 0.41</code><br>top命令的顶部显示与uptime命令相似的输出<br>这些字段显示：</p><p>当前时间</p><ul><li>系统已运行的时间</li><li>当前登录用户的数量</li><li>相应最近5、10和15分钟内的平均负载。</li><li>可以使用’l’命令切换uptime的显示。</li></ul><p>09:40:41 — 当前系统时间<br>2 days, 15:45— 系统已经运行2天了15小时45分钟（在这期间没有重启过）<br>2 users — 当前有2个用户登录系统<br>load average:0.25, 0.41, 0.41— load average后面的三个数分别是5分钟、10分钟、15分钟的负载情况。<br>load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</p><h5 id="1-2-任务"><a href="#1-2-任务" class="headerlink" title="1.2 任务:"></a>1.2 任务:</h5><p><code>Tasks: 239 total,   1 running, 238 sleeping,   0 stopped,   0 zombie</code></p><p>Tasks — 任务（进程），系统现在共有239个进程，其中处于运行中的有1个，238个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。</p><p>第二行显示的是任务或者进程的总结。进程可以处于不同的状态。这里显示了全部进程的数量。除此之外，还有正在运行、睡眠、停止、僵尸进程的数量（僵尸是一种进程的状态）。这些进程概括信息可以用’t’切换显示</p><h5 id="1-3-CPU-状态"><a href="#1-3-CPU-状态" class="headerlink" title="1.3 CPU 状态:"></a>1.3 CPU 状态:</h5><p><code>%Cpu(s):  7.3 us,  2.2 sy,  0.0 ni, 90.5 id,  0.0 wa,  0.0 hi,  0.1 si,  0.0 st</code></p><p>这里显示不同模式下所占cpu时间百分比，这些不同的cpu时间表示：<br>us, user： 运行(未调整优先级的) 用户进程的CPU时间<br>sy，system: 运行内核进程的CPU时间<br>ni，niced：运行已调整优先级的用户进程的CPU时间<br>wa，IO wait: 用于等待IO完成的CPU时间<br>hi：处理硬件中断的CPU时间<br>si: 处理软件中断的CPU时间<br>st：这个虚拟机被hypervisor偷去的CPU时间（译注：如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的）。<br>可以使用’t’命令切换显示。</p><p>7.3% us — 用户空间占用CPU的百分比。<br>2.2% sy — 内核空间占用CPU的百分比。<br>0.0% ni — 改变过优先级的进程占用CPU的百分比<br>90.5% id — 空闲CPU百分比<br>0.0% wa — IO等待占用CPU的百分比<br>0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比<br>0.1% si — 软中断（Software Interrupts）占用CPU的百分比<br>在这里CPU的使用比率和windows概念不同，如果你不理解用户空间和内核空间，需要充充电了。</p><h5 id="1-4-内存使用"><a href="#1-4-内存使用" class="headerlink" title="1.4 内存使用:"></a>1.4 内存使用:</h5><p><code>KiB Mem :  8009768 total,   674540 free,  6877808 used,   457420 buff/cache</code><br><code>KiB Swap:  6291452 total,  5215484 free,  1075968 used.   708664 avail Mem</code></p><p>接下来两行显示内存使用率，有点像’free’命令。第一行是物理内存使用，第二行是虚拟内存使用(交换空间)。</p><p>物理内存显示如下:全部可用内存、已使用内存、空闲内存、缓冲内存。相似地：交换部分显示的是：全部、已使用、空闲和缓冲交换空间。</p><p>内存显示可以用’m’命令切换。</p><p>8009768k total — 物理内存总量<br>6877808k used — 使用中的内存总量<br>674540k free — 空闲内存总量<br>457420k buffers — 缓存的内存量 </p><p>swap交换分区<br>6291452k total — 交换区总量<br>1075968k used — 使用的交换区总量<br>5215484k free — 空闲交换区总量<br>708664k cached — 缓冲的交换区总量</p><p>这里要说明的是不能用windows的内存概念理解这些数据，如果按windows的方式此台服务器“危矣”：8G的内存总量只剩下530M的可用内存。Linux的内存管理有其特殊性，复杂点需要一本书来说明，这里只是简单说点和我们传统概念（windows）的不同。</p><p>第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。</p><p>如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：</p><p>674540+457420+708664= 1797M。</p><p>对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。</p><h5 id="1-5-各进程（任务）的状态监控"><a href="#1-5-各进程（任务）的状态监控" class="headerlink" title="1.5 各进程（任务）的状态监控:"></a>1.5 各进程（任务）的状态监控:</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">1612 couchba+  20   0 1970628 608324   1880 S  13.6  7.6 905:12.91 beam.smp                                                                                                                                      </span><br><span class="line">1932 couchba+  20   0  927008 119432   4496 S  10.9  1.5 359:43.62 indexer                                                                                                                                       </span><br><span class="line">1980 couchba+  20   0 1844964 164968   1024 S   4.3  2.1 138:56.54 memcached                                                                                                                                     </span><br><span class="line">1933 couchba+  20   0  814696 246604   1492 S   3.6  3.1 120:51.86 projector                                                                                                                                     </span><br><span class="line">1046 root      20   0 1296944  41968  10024 S   2.0  0.5 358:00.09 auditbeat</span><br></pre></td></tr></table></figure><p>PID：进程ID，进程的唯一标识符</p><p>USER：进程所有者的实际用户名。</p><p>PR：进程的调度优先级。这个字段的一些值是’rt’。这意味这这些进程运行在实时态。</p><p>NI：进程的nice值（优先级）。越小的值意味着越高的优先级。负值表示高优先级，正值表示低优先级</p><p>VIRT：进程使用的虚拟内存。进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</p><p>RES：驻留内存大小。驻留内存是任务使用的非交换物理内存大小。进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</p><p>SHR：SHR是进程使用的共享内存。共享内存大小，单位kb</p><p>S：这个是进程的状态。它有以下不同的值:</p><p>D - 不可中断的睡眠态。<br>R – 运行态<br>S – 睡眠态<br>T – 被跟踪或已停止<br>Z – 僵尸态<br>%CPU：自从上一次更新时到现在任务所使用的CPU时间百分比。</p><p>%MEM：进程使用的可用物理内存百分比。</p><p>TIME+：任务启动后到现在所使用的全部CPU时间，精确到百分之一秒。</p><p>COMMAND：运行进程所使用的命令。进程名称（命令名/命令行）</p><p>还有许多在默认情况下不会显示的输出，它们可以显示进程的页错误、有效组和组ID和其他更多的信息。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Linux-top命令详解&quot;&gt;&lt;a href=&quot;#Linux-top命令详解&quot; class=&quot;headerlink&quot; title=&quot;Linux top命令详解&quot;&gt;&lt;/a&gt;Linux top命令详解&lt;/h3&gt;&lt;p&gt;top命令经常用来监控&lt;a href=&quot;http:/
      
    
    </summary>
    
      <category term="Linux" scheme="http://macintosh-c.coding.me/categories/Linux/"/>
    
    
      <category term="Linux基础" scheme="http://macintosh-c.coding.me/tags/Linux%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Mac下安装kafka</title>
    <link href="http://macintosh-c.coding.me/2020/07/06/mq/Kafka/Mac%E4%B8%8B%E5%AE%89%E8%A3%85kafka/"/>
    <id>http://macintosh-c.coding.me/2020/07/06/mq/Kafka/Mac下安装kafka/</id>
    <published>2020-07-06T14:14:52.000Z</published>
    <updated>2020-07-06T02:24:17.734Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Mac下安装kafka"><a href="#Mac下安装kafka" class="headerlink" title="Mac下安装kafka"></a>Mac下安装kafka</h4><p>通过brew命令方式来安装</p><ol><li><p>安装homebrew：略</p></li><li><p>通过Brew指令安装kafka<br>brew install kafka</p><p>zookeeper安装后的路径为:/usr/local/Cellar/zookeeper/3.4.13</p><p>kafka安装后的路径为：/usr/local/Cellar/kafka/2.2.1 (版本根据安装版本确定)</p></li><li><p>启动kafka</p><p>==&gt; <strong>zookeeper</strong></p><p>To have launchd start zookeeper now and restart at login:</p><p> brew services start zookeeper</p><p>Or, if you don’t want/need a background service you can just run:</p><p> zkServer start</p><p>==&gt; <strong>kafka</strong></p><p>To have launchd start kafka now and restart at login:</p><p> brew services start kafka</p><p>Or, if you don’t want/need a background service you can just run:</p><p> zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties &amp; kafka-server-start /usr/local/etc/kafka/server.properties</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Mac下安装kafka&quot;&gt;&lt;a href=&quot;#Mac下安装kafka&quot; class=&quot;headerlink&quot; title=&quot;Mac下安装kafka&quot;&gt;&lt;/a&gt;Mac下安装kafka&lt;/h4&gt;&lt;p&gt;通过brew命令方式来安装&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装ho
      
    
    </summary>
    
      <category term="kafka" scheme="http://macintosh-c.coding.me/categories/kafka/"/>
    
    
      <category term="kafka安装" scheme="http://macintosh-c.coding.me/tags/kafka%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot常用注解</title>
    <link href="http://macintosh-c.coding.me/2020/07/01/spring/Springboot/springboot%E6%A0%87%E7%AD%BE2/"/>
    <id>http://macintosh-c.coding.me/2020/07/01/spring/Springboot/springboot标签2/</id>
    <published>2020-07-01T03:29:05.000Z</published>
    <updated>2020-06-30T15:17:26.287Z</updated>
    
    <content type="html"><![CDATA[<p>继于上一篇的思考，继续加强了对springboot中常用注解的学习，总结如下：</p><p>Spring Boot中的常用注解有：@SpringBootApplication、@Repository、@Service、@RestController、@ResponseBody、@Component、@ComponentScan等等。</p><p>1、@SpringBootApplication</p><p>这个注解是Spring Boot最核心的注解，用在 Spring Boot的主类上，标识这是一个 Spring Boot 应用，用来开启 Spring Boot 的各项能力。实际上这个注解是@Configuration,@EnableAutoConfiguration,@ComponentScan三个注解的组合。由于这些注解一般都是一起使用，所以Spring Boot提供了一个统一的注解@SpringBootApplication。</p><p>2、@EnableAutoConfiguration</p><p>允许 Spring Boot 自动配置注解，开启这个注解之后，Spring Boot 就能根据当前类路径下的包或者类来配置 Spring Bean。</p><p>如：当前类路径下有 Mybatis 这个 JAR 包，MybatisAutoConfiguration 注解就能根据相关参数来配置 Mybatis 的各个 Spring Bean。</p><p>@EnableAutoConfiguration实现的关键在于引入了AutoConfigurationImportSelector，其核心逻辑为selectImports方法，逻辑大致如下：</p><p>●　从配置文件META-INF/spring.factories加载所有可能用到的自动配置类；</p><p>●　去重，并将exclude和excludeName属性携带的类排除；</p><p>●　过滤，将满足条件（@Conditional）的自动配置类返回；</p><p>3、@Configuration</p><p>用于定义配置类，指出该类是 Bean 配置的信息源，相当于传统的xml配置文件，一般加在主类上。如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。</p><p>4、@ComponentScan</p><p>组件扫描。让spring Boot扫描到Configuration类并把它加入到程序上下文。</p><p>@ComponentScan注解默认就会装配标识了@Controller，@Service，@Repository，@Component注解的类到spring容器中。</p><p>5、@Repository</p><p>用于标注数据访问组件，即DAO组件。</p><p>使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。</p><p>6、@Service</p><p>一般用于修饰service层的组件</p><p>7、@RestController</p><p>用于标注控制层组件(如struts中的action)，表示这是个控制器bean,并且是将函数的返回值直 接填入HTTP响应体中,是REST风格的控制器；它是@Controller和@ResponseBody的合集。</p><p>8、@ResponseBody</p><p>表示该方法的返回结果直接写入HTTP response body中</p><p>一般在异步获取数据时使用，在使用@RequestMapping后，返回值通常解析为跳转路径，加上@responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。比如异步获取json数据，加上@responsebody后，会直接返回json数据。</p><p>9、@Component</p><p>泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。</p><p>10、@Bean</p><p>相当于XML中的,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理。</p><p>11、@AutoWired</p><p>byType方式。把配置好的Bean拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。</p><p>当加上（required=false）时，就算找不到bean也不报错。</p><p>12、@Qualifier</p><p>当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用</p><p>13、@Resource(name=“name”,type=“type”)</p><p>没有括号内内容的话，默认byName。与@Autowired干类似的事。</p><p>14、@RequestMapping</p><p>RequestMapping是一个用来处理请求地址映射的注解；提供路由信息，负责URL到Controller中的具体函数的映射，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。</p><p>15、@RequestParam</p><p>用在方法的参数前面。例：<br><code>@RequestParam String a =request.getParameter(&quot;a&quot;)。</code></p><p>16、@PathVariable</p><p>路径变量。参数与大括号里的名字一样要相同。例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RequestMapping(&quot;user/get/mac/&#123;macAddress&#125;&quot;)</span><br><span class="line">public String getByMacAddress(@PathVariable String macAddress)&#123;</span><br><span class="line"></span><br><span class="line">　　//do something;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>17、@Profiles</p><p>Spring Profiles提供了一种隔离应用程序配置的方式，并让这些配置只能在特定的环境下生效。</p><p>任何@Component或@Configuration都能被@Profile标记，从而限制加载它的时机。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">@Profile(&quot;prod&quot;)</span><br><span class="line">public class ProductionConfiguration &#123;</span><br><span class="line"></span><br><span class="line">    // ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>18、@ConfigurationProperties</p><p>Spring Boot可使用注解的方式将自定义的properties文件映射到实体bean中，比如config.properties文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">@Data</span><br><span class="line">@ConfigurationProperties(&quot;rocketmq.consumer&quot;)</span><br><span class="line">public class RocketMQConsumerProperties extends RocketMQProperties &#123;</span><br><span class="line"></span><br><span class="line">    private boolean enabled = true;</span><br><span class="line"></span><br><span class="line">    private String consumerGroup;</span><br><span class="line"></span><br><span class="line">    private MessageModel messageModel = MessageModel.CLUSTERING;</span><br><span class="line"></span><br><span class="line">    private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;</span><br><span class="line"></span><br><span class="line">    private int consumeThreadMin = 20;</span><br><span class="line"></span><br><span class="line">    private int consumeThreadMax = 64;</span><br><span class="line"></span><br><span class="line">    private int consumeConcurrentlyMaxSpan = 2000;</span><br><span class="line"></span><br><span class="line">    private int pullThresholdForQueue = 1000;</span><br><span class="line"></span><br><span class="line">    private int pullInterval = 0;</span><br><span class="line"></span><br><span class="line">    private int consumeMessageBatchMaxSize = 1;</span><br><span class="line"></span><br><span class="line">    private int pullBatchSize = 32;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>参考地址：<a href="https://blog.csdn.net/Ellen5203/article/details/105662850" target="_blank" rel="noopener">https://blog.csdn.net/Ellen5203/article/details/105662850</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;继于上一篇的思考，继续加强了对springboot中常用注解的学习，总结如下：&lt;/p&gt;
&lt;p&gt;Spring Boot中的常用注解有：@SpringBootApplication、@Repository、@Service、@RestController、@ResponseBo
      
    
    </summary>
    
      <category term="Springboot" scheme="http://macintosh-c.coding.me/categories/Springboot/"/>
    
    
      <category term="Springboot" scheme="http://macintosh-c.coding.me/tags/Springboot/"/>
    
  </entry>
  
</feed>
